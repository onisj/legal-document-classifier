{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legal Document Classifier - NLP Code Challenge\n",
    "\n",
    "## Objective\n",
    "Develop a robust NLP pipeline to classify legal case reports into areas of law using the provided dataset (`sample_200_rows.csv`). The pipeline includes preprocessing, modeling, evaluation, and a bonus API for inference.\n",
    "\n",
    "## Dataset Overview\n",
    "- **Columns**: `case_title`, `suitno`, `introduction`, `facts`, `issues`, `decision`, `full_report`\n",
    "- **Input**: `full_report` (text of the legal judgment)\n",
    "- **Label**: Area of law extracted from `introduction` (e.g., Civil Procedure, Enforcement of Fundamental Rights)\n",
    "\n",
    "## Approach\n",
    "1. **Preprocessing**: Clean `full_report`, extract and standardize labels, handle imbalance.\n",
    "2. **Modeling**: Use TF-IDF with Logistic Regression, SVM, Random Forest, and fine-tune BERT.\n",
    "3. **Evaluation**: Assess with Accuracy, F1-Score, Confusion Matrix, and visualizations.\n",
    "4. **Inference**: Save models for API use in `app/api.py`.\n",
    "\n",
    "## Evaluation Criteria\n",
    "- Data Preprocessing: 20%\n",
    "- Model Performance: 30%\n",
    "- Code Quality & Structure: 20%\n",
    "- Clarity of Comments/README: 10%\n",
    "- Bonus API: 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import re\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import psutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from nlpaug.augmenter.word import SynonymAug\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "\n",
    "import torch\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x13d3352f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_title</th>\n",
       "      <th>suitno</th>\n",
       "      <th>introduction</th>\n",
       "      <th>facts</th>\n",
       "      <th>issues</th>\n",
       "      <th>decision</th>\n",
       "      <th>full_report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASSET MANAGEMENT GROUP LIMITED v. GENESISCORP ...</td>\n",
       "      <td>CA/L/236M/95</td>\n",
       "      <td>This appeal borders on Civil Procedure.\\n</td>\n",
       "      <td>The appellant as Plaintiff before the Lagos Hi...</td>\n",
       "      <td>The Appellant formulated the following issues ...</td>\n",
       "      <td>On the whole, the Court of Appeal held that th...</td>\n",
       "      <td>GEORGE ADESOLA&amp;nbsp;OGUNTADE, J.C.A. (Deliveri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JAMES EBELE &amp; ANOR v. ROBERT IKWEKI &amp; ORS</td>\n",
       "      <td>CA/B/53M/2006</td>\n",
       "      <td>This is a ruling on an Application seeking Lea...</td>\n",
       "      <td>The present application flows from the Judgmen...</td>\n",
       "      <td>The Court determined the proprietary or otherw...</td>\n",
       "      <td>In the final analysis, the Court of Appeal hel...</td>\n",
       "      <td>\\nCHIOMA EGONDU NWOSU-IHEME&amp;nbsp;J.C.A.  (Deli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CENTRAL BANK OF NIGERIA v. MR TOMMY OKECHUKWU ...</td>\n",
       "      <td>CA/K/304/2020</td>\n",
       "      <td>This appeal borders on propriety of requiremen...</td>\n",
       "      <td>This appeal emanated from the decision of the ...</td>\n",
       "      <td>The Court of Appeal determined the appeal base...</td>\n",
       "      <td>In the end, the Court of Appeal resolved the s...</td>\n",
       "      <td>PETER OYINKENIMIEMI AFFEN, J.C.A. (Delivering ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOHAMMED AUWAL &amp; ORS v. THE FEDERAL REPUBLIC O...</td>\n",
       "      <td>CA/J/183C/2011</td>\n",
       "      <td>This appeal borders on Criminal Law and Proced...</td>\n",
       "      <td>This appeal is against the judgment of the Fed...</td>\n",
       "      <td>The Court determined the appeal on the followi...</td>\n",
       "      <td>In conclusion, the appeal was dismissed.\\n</td>\n",
       "      <td>IBRAHIM SHATA BDLIYA, J.C.A. (Deliveringthe Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNITED BANK FOR AFRICA PLC &amp; ORS v. MR. UGOCHU...</td>\n",
       "      <td>CA/OW/385M/2012</td>\n",
       "      <td>This appeal borders on Enforcement of Fundamen...</td>\n",
       "      <td>This is an appeal against the judgment of NGOZ...</td>\n",
       "      <td>Appellant formulated 4 issues while the Respon...</td>\n",
       "      <td>On the whole, the Court found no merit in the ...</td>\n",
       "      <td>FREDERICK OZIAKPONO&amp;nbsp;OHO, J.C.A. (Deliveri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          case_title           suitno  \\\n",
       "0  ASSET MANAGEMENT GROUP LIMITED v. GENESISCORP ...     CA/L/236M/95   \n",
       "1          JAMES EBELE & ANOR v. ROBERT IKWEKI & ORS    CA/B/53M/2006   \n",
       "2  CENTRAL BANK OF NIGERIA v. MR TOMMY OKECHUKWU ...    CA/K/304/2020   \n",
       "3  MOHAMMED AUWAL & ORS v. THE FEDERAL REPUBLIC O...   CA/J/183C/2011   \n",
       "4  UNITED BANK FOR AFRICA PLC & ORS v. MR. UGOCHU...  CA/OW/385M/2012   \n",
       "\n",
       "                                        introduction  \\\n",
       "0          This appeal borders on Civil Procedure.\\n   \n",
       "1  This is a ruling on an Application seeking Lea...   \n",
       "2  This appeal borders on propriety of requiremen...   \n",
       "3  This appeal borders on Criminal Law and Proced...   \n",
       "4  This appeal borders on Enforcement of Fundamen...   \n",
       "\n",
       "                                               facts  \\\n",
       "0  The appellant as Plaintiff before the Lagos Hi...   \n",
       "1  The present application flows from the Judgmen...   \n",
       "2  This appeal emanated from the decision of the ...   \n",
       "3  This appeal is against the judgment of the Fed...   \n",
       "4  This is an appeal against the judgment of NGOZ...   \n",
       "\n",
       "                                              issues  \\\n",
       "0  The Appellant formulated the following issues ...   \n",
       "1  The Court determined the proprietary or otherw...   \n",
       "2  The Court of Appeal determined the appeal base...   \n",
       "3  The Court determined the appeal on the followi...   \n",
       "4  Appellant formulated 4 issues while the Respon...   \n",
       "\n",
       "                                            decision  \\\n",
       "0  On the whole, the Court of Appeal held that th...   \n",
       "1  In the final analysis, the Court of Appeal hel...   \n",
       "2  In the end, the Court of Appeal resolved the s...   \n",
       "3         In conclusion, the appeal was dismissed.\\n   \n",
       "4  On the whole, the Court found no merit in the ...   \n",
       "\n",
       "                                         full_report  \n",
       "0  GEORGE ADESOLA&nbsp;OGUNTADE, J.C.A. (Deliveri...  \n",
       "1  \\nCHIOMA EGONDU NWOSU-IHEME&nbsp;J.C.A.  (Deli...  \n",
       "2  PETER OYINKENIMIEMI AFFEN, J.C.A. (Delivering ...  \n",
       "3  IBRAHIM SHATA BDLIYA, J.C.A. (Deliveringthe Le...  \n",
       "4  FREDERICK OZIAKPONO&nbsp;OHO, J.C.A. (Deliveri...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('../data/sample_200_rows.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (200, 7)\n",
      "\n",
      "Initial Label Distribution:\n",
      "This appeal borders on Civil Procedure.\\n                                                   19\n",
      "This appeal borders on Civil Procedure.                                                     13\n",
      "This appeal borders on Land Law.\\n                                                           8\n",
      "This appeal borders on Election Petition.\\n                                                  7\n",
      "This appeal borders on civil procedure.                                                      6\n",
      "                                                                                            ..\n",
      "This appeal borders on the issue of locus standi to challenge a political party primary.     1\n",
      "This is an appeal borders on Criminal Law and Procedure.\\n                                   1\n",
      "This appeal borders on Award of Damages.\\n                                                   1\n",
      "This appeal borders on the issue of jurisdiction.                                            1\n",
      "The appeal borders on Enforcement of Fundamental Human Rights.                               1\n",
      "Name: introduction, Length: 127, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "print('Dataset Shape:', df.shape)\n",
    "print('\\nInitial Label Distribution:')\n",
    "print(df['introduction'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by removing special characters, citations, HTML entities, and normalizing spaces.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'&\\w+;', ' ', text)  # Remove HTML entities\n",
    "    text = re.sub(r'\\[\\d{4}\\].*?\\(pt\\.\\s*\\d+\\)', ' ', text)  # Remove citations\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)  # Remove special characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Normalize spaces\n",
    "    if not text:\n",
    "        return ''\n",
    "    return text\n",
    "\n",
    "df['full_report_cleaned'] = df['full_report'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced label extraction\n",
    "def extract_label(intro):\n",
    "    \"\"\"Extract and standardize area of law with comprehensive keywords and NLP fallback.\"\"\"\n",
    "    if pd.isna(intro):\n",
    "        return 'Unknown'\n",
    "    intro = intro.lower().strip()\n",
    "    keywords = {\n",
    "        'civil procedure': 'Civil Procedure',\n",
    "        'enforcement of fundamental rights': 'Enforcement of Fundamental Rights',\n",
    "        'election petition': 'Election Petition',\n",
    "        'garnishee proceedings': 'Garnishee Proceedings',\n",
    "        'criminal law': 'Criminal Law',\n",
    "        'company law': 'Company Law',\n",
    "        'land law': 'Property Law',\n",
    "        'jurisdiction': 'Civil Procedure',\n",
    "        'damages': 'Civil Law',\n",
    "    }\n",
    "    for key, value in keywords.items():\n",
    "        if key in intro:\n",
    "            return value\n",
    "    # Fallback: Use simple NLP to infer from common terms\n",
    "    if 'right' in intro or 'human' in intro:\n",
    "        return 'Enforcement of Fundamental Rights'\n",
    "    return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply label extraction to the dataset\n",
    "df['label'] = df['introduction'].apply(extract_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data preprocessing completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with empty full_report and check final distribution\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "assert df['full_report_cleaned'].str.len().min() > 0, \"Empty cleaned reports detected\"\n",
    "logging.info(\"Data preprocessing completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize label distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "df['label'].value_counts().plot(kind='bar')\n",
    "plt.title('Label Distribution After Extraction')\n",
    "plt.xlabel('Area of Law')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visuals/label_distribution.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modeling - TF-IDF + Traditional ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution Before Merging (Training 1):\n",
      " Other                                97\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Garnishee Proceedings                 1\n",
      "Civil Law                             1\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for first training\n",
    "X_1 = df['full_report_cleaned']\n",
    "y_1 = df['label']\n",
    "\n",
    "# Check label distribution and merge rare classes (fewer than 2 instances)\n",
    "label_counts_1 = y_1.value_counts()\n",
    "print(\"Label Distribution Before Merging (Training 1):\\n\", label_counts_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging rare classes (fewer than 2 instances) for Training 1: ['Garnishee Proceedings', 'Civil Law']\n",
      "Label Distribution After Merging (Training 1):\n",
      " Other                                99\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify classes with fewer than 2 instances\n",
    "rare_classes_1 = label_counts_1[label_counts_1 < 2].index\n",
    "if len(rare_classes_1) > 0:\n",
    "    print(f\"Merging rare classes (fewer than 2 instances) for Training 1: {list(rare_classes_1)}\")\n",
    "    y_merged_1 = y_1.copy()\n",
    "    y_merged_1[y_merged_1.isin(rare_classes_1)] = 'Other'\n",
    "else:\n",
    "    print(\"No rare classes found for Training 1.\")\n",
    "    y_merged_1 = y_1\n",
    "\n",
    "# Verify new distribution\n",
    "print(\"Label Distribution After Merging (Training 1):\\n\", y_merged_1.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Label Distribution (Training 1):\n",
      " 1    79\n",
      "0    39\n",
      "4    15\n",
      "5    12\n",
      "2     8\n",
      "3     7\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Test Label Distribution (Training 1):\n",
      " 1    20\n",
      "0    10\n",
      "4     3\n",
      "5     3\n",
      "2     2\n",
      "3     2\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "label_map_1 = {label: idx for idx, label in enumerate(y_merged_1.unique())}\n",
    "y_encoded_1 = y_merged_1.map(label_map_1)\n",
    "\n",
    "# Split data\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_encoded_1, test_size=0.2, random_state=42, stratify=y_encoded_1)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "vectorizer_1 = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 2))\n",
    "X_train_tfidf_1 = vectorizer_1.fit_transform(X_train_1)\n",
    "X_test_tfidf_1 = vectorizer_1.transform(X_test_1)\n",
    "\n",
    "# Verify split distributions\n",
    "print(\"\\nTrain Label Distribution (Training 1):\\n\", y_train_1.value_counts())\n",
    "print(\"\\nTest Label Distribution (Training 1):\\n\", y_test_1.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Label Distribution Before SMOTE (Training 1):\n",
      " 1    79\n",
      "0    39\n",
      "4    15\n",
      "5    12\n",
      "2     8\n",
      "3     7\n",
      "Name: label, dtype: int64\n",
      "Smallest class size in y_train (Training 1): 7\n",
      "Using k_neighbors=5 for SMOTE (Training 1)\n",
      "\n",
      "Training Set Label Distribution After SMOTE (Training 1):\n",
      " 0    79\n",
      "1    79\n",
      "4    79\n",
      "5    79\n",
      "2    79\n",
      "3    79\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check the distribution of classes in y_train\n",
    "print(\"Training Set Label Distribution Before SMOTE (Training 1):\\n\", y_train_1.value_counts())\n",
    "\n",
    "# Determine the smallest class size\n",
    "min_class_size_1 = y_train_1.value_counts().min()\n",
    "print(f\"Smallest class size in y_train (Training 1): {min_class_size_1}\")\n",
    "\n",
    "# Handle classes with very few samples\n",
    "if min_class_size_1 < 2:\n",
    "    raise ValueError(\"A class in y_train has fewer than 2 samples, which SMOTE cannot handle. Consider merging more classes or removing stratification.\")\n",
    "\n",
    "# Adjust k_neighbors for SMOTE\n",
    "k_neighbors_1 = min(min_class_size_1 - 1, 5)\n",
    "print(f\"Using k_neighbors={k_neighbors_1} for SMOTE (Training 1)\")\n",
    "\n",
    "# Handle imbalance with SMOTE\n",
    "smote_1 = SMOTE(random_state=42, k_neighbors=k_neighbors_1)\n",
    "X_train_tfidf_balanced_1, y_train_balanced_1 = smote_1.fit_resample(X_train_tfidf_1, y_train_1)\n",
    "\n",
    "# Verify the balanced distribution\n",
    "print(\"\\nTraining Set Label Distribution After SMOTE (Training 1):\\n\", pd.Series(y_train_balanced_1).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate multiple models\n",
    "models_1 = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'SVM': SVC(kernel='linear', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance (Training 1):\n",
      "Accuracy: 0.6500\n",
      "F1-Score: 0.6560\n",
      "Confusion Matrix:\n",
      "[[ 7  2  0  0  0  1]\n",
      " [ 7 11  0  0  0  2]\n",
      " [ 0  1  1  0  0  0]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  1  0  0  0  2]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.50      0.70      0.58        10\n",
      "                            Other       0.73      0.55      0.63        20\n",
      "                     Criminal Law       1.00      0.50      0.67         2\n",
      "Enforcement of Fundamental Rights       1.00      1.00      1.00         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.40      0.67      0.50         3\n",
      "\n",
      "                         accuracy                           0.65        40\n",
      "                        macro avg       0.77      0.74      0.73        40\n",
      "                     weighted avg       0.70      0.65      0.66        40\n",
      "\n",
      "\n",
      "SVM Performance (Training 1):\n",
      "Accuracy: 0.6250\n",
      "F1-Score: 0.6252\n",
      "Confusion Matrix:\n",
      "[[ 7  3  0  0  0  0]\n",
      " [ 7 12  0  0  0  1]\n",
      " [ 0  1  1  0  0  0]\n",
      " [ 0  1  0  1  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  2  0  0  0  1]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.50      0.70      0.58        10\n",
      "                            Other       0.63      0.60      0.62        20\n",
      "                     Criminal Law       1.00      0.50      0.67         2\n",
      "Enforcement of Fundamental Rights       1.00      0.50      0.67         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.50      0.33      0.40         3\n",
      "\n",
      "                         accuracy                           0.62        40\n",
      "                        macro avg       0.77      0.61      0.66        40\n",
      "                     weighted avg       0.65      0.62      0.63        40\n",
      "\n",
      "\n",
      "Random Forest Performance (Training 1):\n",
      "Accuracy: 0.5750\n",
      "F1-Score: 0.5455\n",
      "Confusion Matrix:\n",
      "[[ 4  5  0  0  0  1]\n",
      " [ 4 15  0  0  0  1]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  1  0  1  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  3  0  0  0  0]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.50      0.40      0.44        10\n",
      "                            Other       0.58      0.75      0.65        20\n",
      "                     Criminal Law       0.00      0.00      0.00         2\n",
      "Enforcement of Fundamental Rights       1.00      0.50      0.67         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.00      0.00      0.00         3\n",
      "\n",
      "                         accuracy                           0.57        40\n",
      "                        macro avg       0.51      0.44      0.46        40\n",
      "                     weighted avg       0.54      0.57      0.55        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store accuracies for first training\n",
    "model_accuracies_1 = {}\n",
    "\n",
    "for name, model in models_1.items():\n",
    "    model.fit(X_train_tfidf_balanced_1, y_train_balanced_1)\n",
    "    y_pred_1 = model.predict(X_test_tfidf_1)\n",
    "    accuracy_1 = accuracy_score(y_test_1, y_pred_1)\n",
    "    model_accuracies_1[name] = accuracy_1\n",
    "    \n",
    "    print(f'\\n{name} Performance (Training 1):')\n",
    "    print(f'Accuracy: {accuracy_1:.4f}')\n",
    "    print(f'F1-Score: {f1_score(y_test_1, y_pred_1, average=\"weighted\"):.4f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test_1, y_pred_1))\n",
    "    \n",
    "    unique_labels_1 = np.unique(y_test_1)\n",
    "    target_names_1 = [list(label_map_1.keys())[label] for label in unique_labels_1]\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test_1, y_pred_1, labels=unique_labels_1, target_names=target_names_1, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observation:\n",
    "\n",
    "The Logistic Regression (Accuracy: 0.6500, F1-Score: 0.6560), SVM (Accuracy: 0.6250, F1-Score: 0.6252), and Random Forest (Accuracy: 0.5750, F1-Score: 0.5455) performances may be improved giving the context of the dataset, and training setup.\n",
    "\n",
    "Improving the performance of your Logistic Regression, SVM, and Random Forest models for the Legal Document Classifier involves addressing the limitations such as: \n",
    "- small dataset size, \n",
    "- class imbalance, and\n",
    "- suboptimal hyperparameters. \n",
    "\n",
    "Below are actionable suggestions and trials to enhance each model's results. These changes focus on: \n",
    "- data augmentation\n",
    "- feature engineering, and\n",
    "- hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution Before Merging (Training 2):\n",
      " Other                                97\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Garnishee Proceedings                 1\n",
      "Civil Law                             1\n",
      "Name: label, dtype: int64\n",
      "Merging rare classes (fewer than 2 instances) for Training 2: ['Garnishee Proceedings', 'Civil Law']\n",
      "Label Distribution After Merging (Training 2):\n",
      " Other                                99\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Train Label Distribution (Training 2):\n",
      " 1    79\n",
      "0    39\n",
      "4    15\n",
      "5    12\n",
      "2     8\n",
      "3     7\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Test Label Distribution (Training 2):\n",
      " 1    20\n",
      "0    10\n",
      "4     3\n",
      "5     3\n",
      "2     2\n",
      "3     2\n",
      "Name: label, dtype: int64\n",
      "Training Set Label Distribution Before SMOTE (Training 2):\n",
      " 1    79\n",
      "0    39\n",
      "4    15\n",
      "5    12\n",
      "2     8\n",
      "3     7\n",
      "Name: label, dtype: int64\n",
      "Smallest class size in y_train (Training 2): 7\n",
      "Using k_neighbors=5 for SMOTE (Training 2)\n",
      "\n",
      "Training Set Label Distribution After SMOTE (Training 2):\n",
      " 0    79\n",
      "1    79\n",
      "4    79\n",
      "5    79\n",
      "2    79\n",
      "3    79\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Reapplying previous steps and incorporating data augmentation via synonym replacement and increasing ngram_range\n",
    "\n",
    "# Prepare data for second training (fine-tuning)\n",
    "X_2 = df['full_report_cleaned']\n",
    "y_2 = df['label']\n",
    "\n",
    "# Check label distribution\n",
    "label_counts_2 = y_2.value_counts()\n",
    "print(\"Label Distribution Before Merging (Training 2):\\n\", label_counts_2)\n",
    "\n",
    "# Identify classes with fewer than 2 instances\n",
    "rare_classes_2 = label_counts_2[label_counts_2 < 2].index\n",
    "if len(rare_classes_2) > 0:\n",
    "    print(f\"Merging rare classes (fewer than 2 instances) for Training 2: {list(rare_classes_2)}\")\n",
    "    y_merged_2 = y_2.copy()\n",
    "    y_merged_2[y_merged_2.isin(rare_classes_2)] = 'Other'\n",
    "else:\n",
    "    print(\"No rare classes found for Training 2.\")\n",
    "    y_merged_2 = y_2\n",
    "\n",
    "# Verify new distribution\n",
    "print(\"Label Distribution After Merging (Training 2):\\n\", y_merged_2.value_counts())\n",
    "\n",
    "\n",
    "### 1. Data augmentation using synonym replacement\n",
    "aug = SynonymAug(aug_p=0.3)\n",
    "X_augmented_2 = [aug.augment(text)[0] for text in X_2]\n",
    "\n",
    "\n",
    "# Encode labels\n",
    "label_map_2 = {label: idx for idx, label in enumerate(y_merged_2.unique())}\n",
    "y_encoded_2 = y_merged_2.map(label_map_2)\n",
    "\n",
    "# Split data\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_augmented_2, y_encoded_2, test_size=0.2, random_state=42, stratify=y_encoded_2)\n",
    "\n",
    "\n",
    "### 2. Feature Engineering:\n",
    "# TF-IDF Vectorization with feature engineering (custom stop words and 3-grams)\n",
    "vectorizer_2 = TfidfVectorizer(max_features=5000, stop_words='english', ngram_range=(1, 3))\n",
    "X_train_tfidf_2 = vectorizer_2.fit_transform(X_train_2)\n",
    "X_test_tfidf_2 = vectorizer_2.transform(X_test_2)\n",
    "\n",
    "\n",
    "# Verify split distributions\n",
    "print(\"\\nTrain Label Distribution (Training 2):\\n\", y_train_2.value_counts())\n",
    "print(\"\\nTest Label Distribution (Training 2):\\n\", y_test_2.value_counts())\n",
    "\n",
    "# Check the distribution of classes in y_train\n",
    "print(\"Training Set Label Distribution Before SMOTE (Training 2):\\n\", y_train_2.value_counts())\n",
    "\n",
    "# Determine the smallest class size\n",
    "min_class_size_2 = y_train_2.value_counts().min()\n",
    "print(f\"Smallest class size in y_train (Training 2): {min_class_size_2}\")\n",
    "\n",
    "# Handle classes with very few samples\n",
    "if min_class_size_2 < 2:\n",
    "    raise ValueError(\"A class in y_train has fewer than 2 samples, which SMOTE cannot handle. Consider merging more classes or removing stratification.\")\n",
    "\n",
    "# Adjust k_neighbors for SMOTE\n",
    "k_neighbors_2 = min(min_class_size_2 - 1, 5)\n",
    "print(f\"Using k_neighbors={k_neighbors_2} for SMOTE (Training 2)\")\n",
    "\n",
    "# Handle imbalance with SMOTE\n",
    "smote_2 = SMOTE(random_state=42, k_neighbors=k_neighbors_2)\n",
    "X_train_tfidf_balanced_2, y_train_balanced_2 = smote_2.fit_resample(X_train_tfidf_2, y_train_2)\n",
    "\n",
    "# Verify the balanced distribution\n",
    "print(\"\\nTraining Set Label Distribution After SMOTE (Training 2):\\n\", pd.Series(y_train_balanced_2).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. **Hyperparameter Tuning with GridSearchCV**\n",
    "\n",
    "- Using GridSearchCV to find optimal parameters for traditional models (Logistic Regression, SVM, Random Forest). \n",
    "- This aims to improve accuracy by testing combinations systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Params (Training 2): {'C': 10.0, 'max_iter': 500}\n",
      "Best SVM Params (Training 2): {'C': 1.0, 'kernel': 'rbf'}\n",
      "Best Random Forest Params (Training 2): {'max_depth': 10, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grids for tuning\n",
    "param_grid_lr = {'C': [0.1, 1.0, 10.0], 'max_iter': [500, 1000]}\n",
    "param_grid_svm = {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'rbf']}\n",
    "param_grid_rf = {'n_estimators': [100, 200], 'max_depth': [10, 20, None]}\n",
    "\n",
    "# Tune Logistic Regression\n",
    "grid_lr = GridSearchCV(LogisticRegression(random_state=42), param_grid_lr, cv=5, scoring='f1_weighted')\n",
    "grid_lr.fit(X_train_tfidf_balanced_2, y_train_balanced_2)\n",
    "best_lr_2 = grid_lr.best_estimator_\n",
    "print(f\"Best Logistic Regression Params (Training 2): {grid_lr.best_params_}\")\n",
    "\n",
    "# Tune SVM\n",
    "grid_svm = GridSearchCV(SVC(random_state=42), param_grid_svm, cv=5, scoring='f1_weighted')\n",
    "grid_svm.fit(X_train_tfidf_balanced_2, y_train_balanced_2)\n",
    "best_svm_2 = grid_svm.best_estimator_\n",
    "print(f\"Best SVM Params (Training 2): {grid_svm.best_params_}\")\n",
    "\n",
    "# Tune Random Forest\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='f1_weighted')\n",
    "grid_rf.fit(X_train_tfidf_balanced_2, y_train_balanced_2)\n",
    "best_rf_2 = grid_rf.best_estimator_\n",
    "print(f\"Best Random Forest Params (Training 2): {grid_rf.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance (Training 2):\n",
      "Accuracy: 0.5500\n",
      "F1-Score: 0.5351\n",
      "Confusion Matrix:\n",
      "[[8 1 0 0 0 1]\n",
      " [9 9 0 0 0 2]\n",
      " [0 2 0 0 0 0]\n",
      " [0 1 0 1 0 0]\n",
      " [0 0 0 0 3 0]\n",
      " [0 2 0 0 0 1]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.47      0.80      0.59        10\n",
      "                            Other       0.60      0.45      0.51        20\n",
      "                     Criminal Law       0.00      0.00      0.00         2\n",
      "Enforcement of Fundamental Rights       1.00      0.50      0.67         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.25      0.33      0.29         3\n",
      "\n",
      "                         accuracy                           0.55        40\n",
      "                        macro avg       0.55      0.51      0.51        40\n",
      "                     weighted avg       0.56      0.55      0.54        40\n",
      "\n",
      "\n",
      "SVM Performance (Training 2):\n",
      "Accuracy: 0.5250\n",
      "F1-Score: 0.3765\n",
      "Confusion Matrix:\n",
      "[[ 0 10  0  0  0  0]\n",
      " [ 0 20  0  0  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  2  0  0  1  0]\n",
      " [ 0  3  0  0  0  0]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.00      0.00      0.00        10\n",
      "                            Other       0.51      1.00      0.68        20\n",
      "                     Criminal Law       0.00      0.00      0.00         2\n",
      "Enforcement of Fundamental Rights       0.00      0.00      0.00         2\n",
      "                Election Petition       1.00      0.33      0.50         3\n",
      "                     Property Law       0.00      0.00      0.00         3\n",
      "\n",
      "                         accuracy                           0.53        40\n",
      "                        macro avg       0.25      0.22      0.20        40\n",
      "                     weighted avg       0.33      0.53      0.38        40\n",
      "\n",
      "\n",
      "Random Forest Performance (Training 2):\n",
      "Accuracy: 0.6000\n",
      "F1-Score: 0.5553\n",
      "Confusion Matrix:\n",
      "[[ 3  6  0  0  0  1]\n",
      " [ 2 17  0  0  0  1]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  1  0  1  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  3  0  0  0  0]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.60      0.30      0.40        10\n",
      "                            Other       0.59      0.85      0.69        20\n",
      "                     Criminal Law       0.00      0.00      0.00         2\n",
      "Enforcement of Fundamental Rights       1.00      0.50      0.67         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.00      0.00      0.00         3\n",
      "\n",
      "                         accuracy                           0.60        40\n",
      "                        macro avg       0.53      0.44      0.46        40\n",
      "                     weighted avg       0.57      0.60      0.56        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define models with tuned parameters\n",
    "models_2 = {\n",
    "    'Logistic Regression': LogisticRegression(penalty='l1', C=best_lr_2.get_params()['C'], solver='liblinear', max_iter=1000, random_state=42),\n",
    "    'SVM': SVC(kernel='rbf', C=best_svm_2.get_params()['C'], gamma='scale', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=best_rf_2.get_params()['n_estimators'], max_depth=best_rf_2.get_params()['max_depth'], random_state=42)\n",
    "}\n",
    "\n",
    "# Dictionary to store accuracies for second training\n",
    "model_accuracies_2 = {}\n",
    "\n",
    "# Train and evaluate each model\n",
    "scaler_2 = StandardScaler(with_mean=False)  # Sparse data handling\n",
    "X_train_tfidf_scaled_2 = scaler_2.fit_transform(X_train_tfidf_balanced_2)\n",
    "X_test_tfidf_scaled_2 = scaler_2.transform(X_test_tfidf_2)\n",
    "\n",
    "for name, model in models_2.items():\n",
    "    if name == 'SVM':\n",
    "        model.fit(X_train_tfidf_scaled_2, y_train_balanced_2)\n",
    "        y_pred_2 = model.predict(X_test_tfidf_scaled_2)\n",
    "    else:\n",
    "        model.fit(X_train_tfidf_balanced_2, y_train_balanced_2)\n",
    "        y_pred_2 = model.predict(X_test_tfidf_2)\n",
    "    \n",
    "    accuracy_2 = accuracy_score(y_test_2, y_pred_2)\n",
    "    model_accuracies_2[name] = accuracy_2\n",
    "    \n",
    "    print(f'\\n{name} Performance (Training 2):')\n",
    "    print(f'Accuracy: {accuracy_2:.4f}')\n",
    "    print(f'F1-Score: {f1_score(y_test_2, y_pred_2, average=\"weighted\"):.4f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test_2, y_pred_2))\n",
    "    \n",
    "    unique_labels_2 = np.unique(y_test_2)\n",
    "    target_names_2 = [list(label_map_2.keys())[label] for label in unique_labels_2]\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test_2, y_pred_2, labels=unique_labels_2, target_names=target_names_2, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Combined Model Performance Summary ===\n",
      "Model                     Train   Accuracy  \n",
      "---------------------------------------------\n",
      "Logistic Regression       1       0.6500    \n",
      "SVM                       1       0.6250    \n",
      "Random Forest             2       0.6000    \n",
      "Random Forest             1       0.5750    \n",
      "Logistic Regression       2       0.5500    \n",
      "SVM                       2       0.5250    \n",
      "\n",
      "✅ Best Model: Logistic Regression from Training 1 with Accuracy: 0.6500\n"
     ]
    }
   ],
   "source": [
    "# Combine accuracies from both LR/SVM/RF trainings to find the overall best model\n",
    "all_accuracies = {}\n",
    "\n",
    "# Add accuracies from first training\n",
    "for name, accuracy in model_accuracies_1.items():\n",
    "    all_accuracies[(name, 1)] = (accuracy, models_1[name], vectorizer_1, X_test_tfidf_1, y_test_1, label_map_1)\n",
    "\n",
    "# Add accuracies from second training\n",
    "for name, accuracy in model_accuracies_2.items():\n",
    "    all_accuracies[(name, 2)] = (accuracy, models_2[name], vectorizer_2, X_test_tfidf_2, y_test_2, label_map_2)\n",
    "\n",
    "# Sort by accuracy descending\n",
    "sorted_models = sorted(all_accuracies.items(), key=lambda x: x[1][0], reverse=True)\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n=== Combined Model Performance Summary ===\")\n",
    "print(f\"{'Model':<25} {'Train':<7} {'Accuracy':<10}\")\n",
    "print(\"-\" * 45)\n",
    "for (name, train_num), (acc, _, _, _, _, _) in sorted_models:\n",
    "    print(f\"{name:<25} {train_num:<7} {acc:<10.4f}\")\n",
    "\n",
    "# Get best model\n",
    "best_model_name, best_training = sorted_models[0][0]\n",
    "best_accuracy, best_model, best_vectorizer, X_test_best, y_test_best, label_map_best = sorted_models[0][1]\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name} from Training {best_training} with Accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Observation for LR/SVM/RF**\n",
    "\n",
    "- LR (Accuracy: 0.6500, F1-Score: 0.6560), SVM (Accuracy: 0.6250, F1-Score: 0.6252), and RF (Accuracy: 0.5750, F1-Score: 0.5455) outperform BERT, reflecting their adaptability to the small, imbalanced dataset.\n",
    "\n",
    "#### **Analysis of the Issue**\n",
    "\n",
    "##### 1. **Dataset Size and Complexity**\n",
    "- **Small Dataset**: 200 samples (160 train, 40 test) suit traditional models better than deep learning, which need larger data.\n",
    "- **Imbalanced Classes**: Uneven distribution (e.g., `Other`: 20, `Civil Procedure`: 10) challenges minority class learning without robust balancing.\n",
    "\n",
    "##### 2. **Training Configuration**\n",
    "- **Hyperparameters**: Default settings (e.g., `max_iter=1000`, `n_estimators=100`) may not be optimal, limiting performance.\n",
    "- **Feature Extraction**: TF-IDF with basic n-grams may miss complex patterns, especially without augmentation.\n",
    "\n",
    "##### 3. **Model Initialization**\n",
    "- **Simplicity**: LR, SVM, and RF have fewer parameters, reducing overfitting on small data compared to BERT.\n",
    "- **Feature Fit**: TF-IDF features align well with traditional models, enhancing their edge.\n",
    "\n",
    "##### 4. **Evaluation Metrics**\n",
    "- **Confusion Matrix**: Models show varied predictions, but minority class performance lags.\n",
    "- **F1-Score**: Reflects decent balance but room for improvement in minority classes.\n",
    "\n",
    "\n",
    "#### **Why LR/SVM/RF Perform Well**\n",
    "- **Data Fit**: Small dataset favors simpler models.\n",
    "- **Feature Effectiveness**: TF-IDF captures key patterns efficiently.\n",
    "- **Robustness**: Less sensitive to hyperparameter tuning than BERT.\n",
    "\n",
    "#### **Improvements to Boost LR/SVM/RF Performance**\n",
    "- Optimize with Optuna, add contextual augmentation, and enhance balancing with SMOTE.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from googletrans import Translator\n",
    "\n",
    "def prepare_data(df, suffix, augment=False, back_translation=False):\n",
    "    \"\"\"\n",
    "    Prepare data for training: merge rare classes, encode labels, and split.\n",
    "    Args:\n",
    "        df: DataFrame with 'full_report_cleaned' and 'label' columns\n",
    "        suffix: Suffix for variable naming (e.g., '_1', '_2', '_3')\n",
    "        augment: If True, apply basic text augmentation (for LR/SVM/RF)\n",
    "        back_translation: If True, apply back-translation (for BERT)\n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test, label_map\n",
    "    \"\"\"\n",
    "    # Extract features and labels\n",
    "    X = df['full_report_cleaned']\n",
    "    y = df['label']\n",
    "\n",
    "    # Check label distribution and merge rare classes (fewer than 2 instances)\n",
    "    label_counts = y.value_counts()\n",
    "    print(f\"Label Distribution Before Merging (Training {suffix}):\\n\", label_counts)\n",
    "\n",
    "    rare_classes = label_counts[label_counts < 2].index\n",
    "    if len(rare_classes) > 0:\n",
    "        print(f\"Merging rare classes (fewer than 2 instances) for Training {suffix}: {list(rare_classes)}\")\n",
    "        y_merged = y.copy()\n",
    "        y_merged[y_merged.isin(rare_classes)] = 'Other'\n",
    "    else:\n",
    "        print(f\"No rare classes found for Training {suffix}.\")\n",
    "        y_merged = y\n",
    "\n",
    "    # Verify new distribution\n",
    "    print(f\"Label Distribution After Merging (Training {suffix}):\\n\", y_merged.value_counts())\n",
    "\n",
    "    # Encode labels after merging\n",
    "    label_map = {label: idx for idx, label in enumerate(y_merged.unique())}\n",
    "    y_encoded = y_merged.map(label_map)\n",
    "\n",
    "    # Apply augmentation if specified\n",
    "    if augment:\n",
    "        # Basic augmentation: duplicate text (for LR/SVM/RF)\n",
    "        X = X.apply(lambda x: x + \" \" + x)\n",
    "\n",
    "    if back_translation:\n",
    "        # Back-translation using googletrans\n",
    "        translator = Translator()\n",
    "        print(f\"Applying back-translation for Training {suffix}...\")\n",
    "        def back_translate(text):\n",
    "            try:\n",
    "                # Translate to French and back to English\n",
    "                fr_text = translator.translate(text, src='en', dest='fr').text\n",
    "                en_text = translator.translate(fr_text, src='fr', dest='en').text\n",
    "                return en_text\n",
    "            except Exception as e:\n",
    "                print(f\"Back-translation error: {e}\")\n",
    "                return text  # Return original text on failure\n",
    "\n",
    "        X = X.apply(back_translate)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "    # Verify split distributions\n",
    "    print(f\"\\nTrain Label Distribution (Training {suffix}):\\n\", y_train.value_counts())\n",
    "    print(f\"\\nTest Label Distribution (Training {suffix}):\\n\", y_test.value_counts())\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import nlpaug.augmenter.word as naw\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def run_lr_svm_rf_training(df, suffix, balance=False, augment=False):\n",
    "    \"\"\"\n",
    "    Run LR/SVM/RF training with specified suffix.\n",
    "    Args:\n",
    "        df: DataFrame with 'full_report_cleaned' and 'label' columns\n",
    "        suffix: Suffix for variable naming (e.g., '_1', '_2', '_3')\n",
    "        balance: If True, apply SMOTE for class balancing\n",
    "        augment: If True, apply contextual augmentation\n",
    "    Returns:\n",
    "        models, vectorizer, model_accuracies, X_test_tfidf, y_test, label_map\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test, label_map = prepare_data(df, suffix, augment=augment)\n",
    "\n",
    "    # Preprocessing: Lemmatization and custom stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    custom_stopwords = set(stopwords.words('english')) - {'not', 'against', 'no'}  # Keep negation words\n",
    "    X_train = X_train.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split() if word.lower() not in custom_stopwords]))\n",
    "    X_test = X_test.apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x.split() if word.lower() not in custom_stopwords]))\n",
    "\n",
    "    # TF-IDF Vectorization with n-grams\n",
    "    vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 3))\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "    # Apply SMOTE if balancing is enabled\n",
    "    if balance:\n",
    "        min_class_size = y_train.value_counts().min()\n",
    "        k_neighbors = min(min_class_size - 1, 5)\n",
    "        smote = SMOTE(random_state=42, k_neighbors=k_neighbors)\n",
    "        X_train_tfidf, y_train = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "    # Hyperparameter tuning with Optuna\n",
    "    def objective(trial, model_name, X_train, y_train, X_test, y_test):\n",
    "        if model_name == 'LogisticRegression':\n",
    "            params = {\n",
    "                'C': trial.suggest_float('C', 0.1, 10.0, log=True),\n",
    "                'max_iter': trial.suggest_int('max_iter', 500, 1500)\n",
    "            }\n",
    "            model = LogisticRegression(**params, class_weight='balanced', random_state=42)\n",
    "        elif model_name == 'SVM':\n",
    "            params = {\n",
    "                'C': trial.suggest_float('C', 0.1, 10.0, log=True),\n",
    "                'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf'])\n",
    "            }\n",
    "            model = SVC(**params, class_weight='balanced', random_state=42)\n",
    "        else:  # RandomForest\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "                'max_depth': trial.suggest_int('max_depth', 10, 50, step=10)\n",
    "            }\n",
    "            model = RandomForestClassifier(**params, class_weight='balanced', random_state=42)\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    models = {}\n",
    "    model_accuracies = {}\n",
    "    for model_name in ['LogisticRegression', 'SVM', 'RandomForest']:\n",
    "        study = optuna.create_study(direction='maximize')\n",
    "        study.optimize(lambda trial: objective(trial, model_name, X_train_tfidf, y_train, X_test_tfidf, y_test), n_trials=20)\n",
    "        best_params = study.best_params\n",
    "\n",
    "        if model_name == 'LogisticRegression':\n",
    "            models[model_name] = LogisticRegression(**best_params, class_weight='balanced', random_state=42)\n",
    "        elif model_name == 'SVM':\n",
    "            models[model_name] = SVC(**best_params, class_weight='balanced', random_state=42)\n",
    "        else:\n",
    "            models[model_name] = RandomForestClassifier(**best_params, class_weight='balanced', random_state=42)\n",
    "\n",
    "        models[model_name].fit(X_train_tfidf, y_train)\n",
    "        y_pred = models[model_name].predict(X_test_tfidf)\n",
    "        model_accuracies[model_name] = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        print(f'\\n{model_name} Performance (Training {suffix}):')\n",
    "        print(f'Accuracy: {model_accuracies[model_name]:.4f}')\n",
    "        print(f'F1-Score: {f1_score(y_test, y_pred, average=\"weighted\"):.4f}')\n",
    "        print('Confusion Matrix:')\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        unique_labels = np.unique(y_test)\n",
    "        target_names = [list(label_map.keys())[label] for label in unique_labels]\n",
    "        print('Classification Report:')\n",
    "        print(classification_report(y_test, y_pred, labels=unique_labels, target_names=target_names, zero_division=0))\n",
    "\n",
    "    return models, vectorizer, model_accuracies, X_test_tfidf, y_test, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution Before Merging (Training _1):\n",
      " Other                                97\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Garnishee Proceedings                 1\n",
      "Civil Law                             1\n",
      "Name: label, dtype: int64\n",
      "Merging rare classes (fewer than 2 instances) for Training _1: ['Garnishee Proceedings', 'Civil Law']\n",
      "Label Distribution After Merging (Training _1):\n",
      " Other                                99\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Train Label Distribution (Training _1):\n",
      " 1    79\n",
      "0    39\n",
      "4    15\n",
      "5    12\n",
      "2     8\n",
      "3     7\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Test Label Distribution (Training _1):\n",
      " 1    20\n",
      "0    10\n",
      "4     3\n",
      "5     3\n",
      "2     2\n",
      "3     2\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 17:25:16,255] A new study created in memory with name: no-name-de2edd95-c73a-4f36-bcc3-a8dc8c9b01b7\n",
      "[I 2025-05-27 17:25:17,117] Trial 0 finished with value: 0.7 and parameters: {'C': 6.02087624130438, 'max_iter': 607}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:17,662] Trial 1 finished with value: 0.625 and parameters: {'C': 1.3398896890313357, 'max_iter': 1421}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:18,454] Trial 2 finished with value: 0.7 and parameters: {'C': 5.290082760844497, 'max_iter': 1397}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:19,393] Trial 3 finished with value: 0.675 and parameters: {'C': 9.876701339686846, 'max_iter': 875}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:19,969] Trial 4 finished with value: 0.65 and parameters: {'C': 1.1447852225437385, 'max_iter': 1200}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:20,252] Trial 5 finished with value: 0.475 and parameters: {'C': 0.23983669998408624, 'max_iter': 904}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:20,873] Trial 6 finished with value: 0.675 and parameters: {'C': 1.8883371003997411, 'max_iter': 599}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:21,756] Trial 7 finished with value: 0.675 and parameters: {'C': 9.565132080938467, 'max_iter': 1038}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:22,323] Trial 8 finished with value: 0.625 and parameters: {'C': 1.3247774917829058, 'max_iter': 941}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:22,612] Trial 9 finished with value: 0.525 and parameters: {'C': 0.3093093865199433, 'max_iter': 530}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:23,332] Trial 10 finished with value: 0.7 and parameters: {'C': 3.4651777025520163, 'max_iter': 682}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:24,263] Trial 11 finished with value: 0.7 and parameters: {'C': 4.081562064448585, 'max_iter': 1471}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:25,383] Trial 12 finished with value: 0.7 and parameters: {'C': 3.9403641982205286, 'max_iter': 1264}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:26,015] Trial 13 finished with value: 0.6 and parameters: {'C': 0.5055891783124101, 'max_iter': 704}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:27,675] Trial 14 finished with value: 0.7 and parameters: {'C': 5.636502295633558, 'max_iter': 1129}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:28,120] Trial 15 finished with value: 0.45 and parameters: {'C': 0.10196612086776273, 'max_iter': 1320}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:29,404] Trial 16 finished with value: 0.7 and parameters: {'C': 2.442264742139608, 'max_iter': 784}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:30,702] Trial 17 finished with value: 0.7 and parameters: {'C': 5.986520925315722, 'max_iter': 1035}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:31,721] Trial 18 finished with value: 0.7 and parameters: {'C': 2.3525331635612847, 'max_iter': 1360}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:32,308] Trial 19 finished with value: 0.625 and parameters: {'C': 0.6742089890190602, 'max_iter': 1114}. Best is trial 0 with value: 0.7.\n",
      "[I 2025-05-27 17:25:33,561] A new study created in memory with name: no-name-d86d4b9f-cf17-407d-b28b-64c808e9f6d7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Performance (Training _1):\n",
      "Accuracy: 0.7000\n",
      "F1-Score: 0.6978\n",
      "Confusion Matrix:\n",
      "[[ 9  1  0  0  0  0]\n",
      " [ 7 11  0  0  0  2]\n",
      " [ 0  1  1  0  0  0]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  1  0  0  0  2]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.56      0.90      0.69        10\n",
      "                            Other       0.79      0.55      0.65        20\n",
      "                     Criminal Law       1.00      0.50      0.67         2\n",
      "Enforcement of Fundamental Rights       1.00      1.00      1.00         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.50      0.67      0.57         3\n",
      "\n",
      "                         accuracy                           0.70        40\n",
      "                        macro avg       0.81      0.77      0.76        40\n",
      "                     weighted avg       0.75      0.70      0.70        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 17:25:35,044] Trial 0 finished with value: 0.6 and parameters: {'C': 5.810148330047386, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:36,542] Trial 1 finished with value: 0.575 and parameters: {'C': 1.0788145201790282, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:38,127] Trial 2 finished with value: 0.45 and parameters: {'C': 0.31875618497925423, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:39,670] Trial 3 finished with value: 0.4 and parameters: {'C': 0.3569090723570402, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:41,040] Trial 4 finished with value: 0.6 and parameters: {'C': 1.2498977017499233, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:42,490] Trial 5 finished with value: 0.5 and parameters: {'C': 0.6839548987867357, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:43,907] Trial 6 finished with value: 0.45 and parameters: {'C': 0.4782172837793923, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:45,650] Trial 7 finished with value: 0.575 and parameters: {'C': 5.820970196125349, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:47,434] Trial 8 finished with value: 0.425 and parameters: {'C': 0.7352900531536878, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:49,344] Trial 9 finished with value: 0.6 and parameters: {'C': 5.768811703972868, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:51,310] Trial 10 finished with value: 0.6 and parameters: {'C': 2.480421763746337, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:53,340] Trial 11 finished with value: 0.325 and parameters: {'C': 0.11784378648578325, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:25:55,039] Trial 12 finished with value: 0.65 and parameters: {'C': 2.2120338058819287, 'kernel': 'linear'}. Best is trial 12 with value: 0.65.\n",
      "[I 2025-05-27 17:25:56,710] Trial 13 finished with value: 0.6 and parameters: {'C': 9.699531768447144, 'kernel': 'linear'}. Best is trial 12 with value: 0.65.\n",
      "[I 2025-05-27 17:25:58,443] Trial 14 finished with value: 0.675 and parameters: {'C': 2.6155614979784647, 'kernel': 'linear'}. Best is trial 14 with value: 0.675.\n",
      "[I 2025-05-27 17:26:00,392] Trial 15 finished with value: 0.65 and parameters: {'C': 2.316751179794034, 'kernel': 'linear'}. Best is trial 14 with value: 0.675.\n",
      "[I 2025-05-27 17:26:02,073] Trial 16 finished with value: 0.65 and parameters: {'C': 2.06000262546696, 'kernel': 'linear'}. Best is trial 14 with value: 0.675.\n",
      "[I 2025-05-27 17:26:03,716] Trial 17 finished with value: 0.65 and parameters: {'C': 3.1656840574768874, 'kernel': 'linear'}. Best is trial 14 with value: 0.675.\n",
      "[I 2025-05-27 17:26:05,526] Trial 18 finished with value: 0.525 and parameters: {'C': 1.4100285493746987, 'kernel': 'rbf'}. Best is trial 14 with value: 0.675.\n",
      "[I 2025-05-27 17:26:07,091] Trial 19 finished with value: 0.625 and parameters: {'C': 3.941322471048027, 'kernel': 'linear'}. Best is trial 14 with value: 0.675.\n",
      "[I 2025-05-27 17:26:08,667] A new study created in memory with name: no-name-0436a952-7e05-4559-853c-f6d8c87fadc4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Performance (Training _1):\n",
      "Accuracy: 0.6750\n",
      "F1-Score: 0.6691\n",
      "Confusion Matrix:\n",
      "[[ 9  1  0  0  0  0]\n",
      " [ 7 12  0  0  0  1]\n",
      " [ 0  1  1  0  0  0]\n",
      " [ 0  1  0  1  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  2  0  0  0  1]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.56      0.90      0.69        10\n",
      "                            Other       0.71      0.60      0.65        20\n",
      "                     Criminal Law       1.00      0.50      0.67         2\n",
      "Enforcement of Fundamental Rights       1.00      0.50      0.67         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.50      0.33      0.40         3\n",
      "\n",
      "                         accuracy                           0.68        40\n",
      "                        macro avg       0.79      0.64      0.68        40\n",
      "                     weighted avg       0.71      0.68      0.67        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 17:26:10,644] Trial 0 finished with value: 0.575 and parameters: {'n_estimators': 143, 'max_depth': 50}. Best is trial 0 with value: 0.575.\n",
      "[I 2025-05-27 17:26:13,150] Trial 1 finished with value: 0.575 and parameters: {'n_estimators': 171, 'max_depth': 10}. Best is trial 0 with value: 0.575.\n",
      "[I 2025-05-27 17:26:14,161] Trial 2 finished with value: 0.6 and parameters: {'n_estimators': 73, 'max_depth': 40}. Best is trial 2 with value: 0.6.\n",
      "[I 2025-05-27 17:26:17,360] Trial 3 finished with value: 0.6 and parameters: {'n_estimators': 251, 'max_depth': 40}. Best is trial 2 with value: 0.6.\n",
      "[I 2025-05-27 17:26:20,944] Trial 4 finished with value: 0.625 and parameters: {'n_estimators': 296, 'max_depth': 40}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:24,325] Trial 5 finished with value: 0.6 and parameters: {'n_estimators': 258, 'max_depth': 20}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:26,121] Trial 6 finished with value: 0.575 and parameters: {'n_estimators': 118, 'max_depth': 30}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:28,900] Trial 7 finished with value: 0.575 and parameters: {'n_estimators': 168, 'max_depth': 30}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:30,146] Trial 8 finished with value: 0.6 and parameters: {'n_estimators': 69, 'max_depth': 50}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:33,208] Trial 9 finished with value: 0.625 and parameters: {'n_estimators': 232, 'max_depth': 40}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:36,893] Trial 10 finished with value: 0.6 and parameters: {'n_estimators': 299, 'max_depth': 20}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:40,062] Trial 11 finished with value: 0.625 and parameters: {'n_estimators': 232, 'max_depth': 40}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:43,916] Trial 12 finished with value: 0.625 and parameters: {'n_estimators': 297, 'max_depth': 40}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:46,463] Trial 13 finished with value: 0.625 and parameters: {'n_estimators': 218, 'max_depth': 50}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:48,726] Trial 14 finished with value: 0.625 and parameters: {'n_estimators': 218, 'max_depth': 30}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:51,439] Trial 15 finished with value: 0.6 and parameters: {'n_estimators': 263, 'max_depth': 40}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:53,659] Trial 16 finished with value: 0.625 and parameters: {'n_estimators': 198, 'max_depth': 20}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:56,382] Trial 17 finished with value: 0.625 and parameters: {'n_estimators': 272, 'max_depth': 50}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:26:58,357] Trial 18 finished with value: 0.6 and parameters: {'n_estimators': 195, 'max_depth': 30}. Best is trial 4 with value: 0.625.\n",
      "[I 2025-05-27 17:27:02,247] Trial 19 finished with value: 0.6 and parameters: {'n_estimators': 288, 'max_depth': 40}. Best is trial 4 with value: 0.625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForest Performance (Training _1):\n",
      "Accuracy: 0.6250\n",
      "F1-Score: 0.5220\n",
      "Confusion Matrix:\n",
      "[[ 2  8  0  0  0  0]\n",
      " [ 0 20  0  0  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  3  0  0  0  0]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       1.00      0.20      0.33        10\n",
      "                            Other       0.57      1.00      0.73        20\n",
      "                     Criminal Law       0.00      0.00      0.00         2\n",
      "Enforcement of Fundamental Rights       0.00      0.00      0.00         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.00      0.00      0.00         3\n",
      "\n",
      "                         accuracy                           0.62        40\n",
      "                        macro avg       0.43      0.37      0.34        40\n",
      "                     weighted avg       0.61      0.62      0.52        40\n",
      "\n",
      "Label Distribution Before Merging (Training _2):\n",
      " Other                                97\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Garnishee Proceedings                 1\n",
      "Civil Law                             1\n",
      "Name: label, dtype: int64\n",
      "Merging rare classes (fewer than 2 instances) for Training _2: ['Garnishee Proceedings', 'Civil Law']\n",
      "Label Distribution After Merging (Training _2):\n",
      " Other                                99\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Train Label Distribution (Training _2):\n",
      " 1    79\n",
      "0    39\n",
      "4    15\n",
      "5    12\n",
      "2     8\n",
      "3     7\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Test Label Distribution (Training _2):\n",
      " 1    20\n",
      "0    10\n",
      "4     3\n",
      "5     3\n",
      "2     2\n",
      "3     2\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 17:27:25,635] A new study created in memory with name: no-name-98910768-c9ed-49f0-b30c-6a65b67d6bdd\n",
      "[I 2025-05-27 17:27:26,901] Trial 0 finished with value: 0.65 and parameters: {'C': 0.22774694956206915, 'max_iter': 1381}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:27:29,752] Trial 1 finished with value: 0.6 and parameters: {'C': 5.693604186732867, 'max_iter': 1209}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:27:30,789] Trial 2 finished with value: 0.65 and parameters: {'C': 0.2944652990894264, 'max_iter': 1449}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:27:33,122] Trial 3 finished with value: 0.65 and parameters: {'C': 2.277953251769215, 'max_iter': 1100}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:27:35,654] Trial 4 finished with value: 0.625 and parameters: {'C': 3.903257833353942, 'max_iter': 509}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:27:37,906] Trial 5 finished with value: 0.675 and parameters: {'C': 0.8828193241516612, 'max_iter': 1496}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:27:39,381] Trial 6 finished with value: 0.65 and parameters: {'C': 0.37671801249962467, 'max_iter': 726}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:27:43,292] Trial 7 finished with value: 0.6 and parameters: {'C': 6.396045910942471, 'max_iter': 839}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:27:45,520] Trial 8 finished with value: 0.675 and parameters: {'C': 1.2727169091089976, 'max_iter': 1058}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:27:48,335] Trial 9 finished with value: 0.65 and parameters: {'C': 3.348839230984976, 'max_iter': 1341}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:27:50,181] Trial 10 finished with value: 0.675 and parameters: {'C': 0.7416087735958153, 'max_iter': 868}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:27:52,246] Trial 11 finished with value: 0.675 and parameters: {'C': 1.2337997116115678, 'max_iter': 1146}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:27:53,239] Trial 12 finished with value: 0.625 and parameters: {'C': 0.10748188106856929, 'max_iter': 974}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:27:54,840] Trial 13 finished with value: 0.675 and parameters: {'C': 1.1444170468652626, 'max_iter': 1263}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:27:56,648] Trial 14 finished with value: 0.675 and parameters: {'C': 0.6288630449210942, 'max_iter': 550}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:27:58,826] Trial 15 finished with value: 0.65 and parameters: {'C': 1.8463337293866362, 'max_iter': 1499}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:28:00,479] Trial 16 finished with value: 0.675 and parameters: {'C': 0.6365599778202363, 'max_iter': 1032}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:28:03,923] Trial 17 finished with value: 0.6 and parameters: {'C': 9.418696943533563, 'max_iter': 633}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:28:05,974] Trial 18 finished with value: 0.65 and parameters: {'C': 1.747937814489409, 'max_iter': 922}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:28:07,290] Trial 19 finished with value: 0.65 and parameters: {'C': 0.14363212135165462, 'max_iter': 1315}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:28:09,726] A new study created in memory with name: no-name-c6d5b55f-1e19-494f-b7e6-239e79e31617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Performance (Training _2):\n",
      "Accuracy: 0.6750\n",
      "F1-Score: 0.6755\n",
      "Confusion Matrix:\n",
      "[[ 8  2  0  0  0  0]\n",
      " [ 7 11  0  0  0  2]\n",
      " [ 0  1  1  0  0  0]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  1  0  0  0  2]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.53      0.80      0.64        10\n",
      "                            Other       0.73      0.55      0.63        20\n",
      "                     Criminal Law       1.00      0.50      0.67         2\n",
      "Enforcement of Fundamental Rights       1.00      1.00      1.00         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.50      0.67      0.57         3\n",
      "\n",
      "                         accuracy                           0.68        40\n",
      "                        macro avg       0.79      0.75      0.75        40\n",
      "                     weighted avg       0.71      0.68      0.68        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 17:28:14,717] Trial 0 finished with value: 0.6 and parameters: {'C': 1.9418738628538537, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:28:23,896] Trial 1 finished with value: 0.625 and parameters: {'C': 0.1856986549111385, 'kernel': 'linear'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:28:31,857] Trial 2 finished with value: 0.575 and parameters: {'C': 0.3107451325966369, 'kernel': 'rbf'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:28:41,563] Trial 3 finished with value: 0.575 and parameters: {'C': 0.16514551100951985, 'kernel': 'linear'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:28:54,030] Trial 4 finished with value: 0.6 and parameters: {'C': 0.10148631029262883, 'kernel': 'rbf'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:28:57,918] Trial 5 finished with value: 0.6 and parameters: {'C': 8.156410817975116, 'kernel': 'linear'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:29:05,602] Trial 6 finished with value: 0.575 and parameters: {'C': 0.2691446142605974, 'kernel': 'rbf'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:29:10,082] Trial 7 finished with value: 0.6 and parameters: {'C': 5.8132606287911095, 'kernel': 'linear'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:29:14,626] Trial 8 finished with value: 0.6 and parameters: {'C': 5.427234649338923, 'kernel': 'linear'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:29:23,424] Trial 9 finished with value: 0.575 and parameters: {'C': 0.14156291723280387, 'kernel': 'linear'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:29:28,950] Trial 10 finished with value: 0.55 and parameters: {'C': 0.7557729656066356, 'kernel': 'rbf'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:29:32,716] Trial 11 finished with value: 0.6 and parameters: {'C': 1.8593570628414122, 'kernel': 'linear'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:29:36,985] Trial 12 finished with value: 0.6 and parameters: {'C': 1.53127779015674, 'kernel': 'linear'}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:29:41,950] Trial 13 finished with value: 0.65 and parameters: {'C': 0.8003490355998726, 'kernel': 'linear'}. Best is trial 13 with value: 0.65.\n",
      "[I 2025-05-27 17:29:47,496] Trial 14 finished with value: 0.625 and parameters: {'C': 0.611212037306119, 'kernel': 'linear'}. Best is trial 13 with value: 0.65.\n",
      "[I 2025-05-27 17:29:52,450] Trial 15 finished with value: 0.65 and parameters: {'C': 0.4150654870596133, 'kernel': 'linear'}. Best is trial 13 with value: 0.65.\n",
      "[I 2025-05-27 17:29:57,297] Trial 16 finished with value: 0.65 and parameters: {'C': 0.46146984038688005, 'kernel': 'linear'}. Best is trial 13 with value: 0.65.\n",
      "[I 2025-05-27 17:30:01,253] Trial 17 finished with value: 0.625 and parameters: {'C': 1.0190957056137235, 'kernel': 'linear'}. Best is trial 13 with value: 0.65.\n",
      "[I 2025-05-27 17:30:05,550] Trial 18 finished with value: 0.55 and parameters: {'C': 3.321746234545926, 'kernel': 'rbf'}. Best is trial 13 with value: 0.65.\n",
      "[I 2025-05-27 17:30:10,865] Trial 19 finished with value: 0.65 and parameters: {'C': 0.39040746907928386, 'kernel': 'linear'}. Best is trial 13 with value: 0.65.\n",
      "[I 2025-05-27 17:30:14,788] A new study created in memory with name: no-name-f8b2ae03-d75b-4af4-bfa0-07c2130a121f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Performance (Training _2):\n",
      "Accuracy: 0.6500\n",
      "F1-Score: 0.6491\n",
      "Confusion Matrix:\n",
      "[[ 8  2  0  0  0  0]\n",
      " [ 6 12  0  0  0  2]\n",
      " [ 0  1  1  0  0  0]\n",
      " [ 0  1  0  1  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  2  0  0  0  1]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.57      0.80      0.67        10\n",
      "                            Other       0.67      0.60      0.63        20\n",
      "                     Criminal Law       1.00      0.50      0.67         2\n",
      "Enforcement of Fundamental Rights       1.00      0.50      0.67         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.33      0.33      0.33         3\n",
      "\n",
      "                         accuracy                           0.65        40\n",
      "                        macro avg       0.76      0.62      0.66        40\n",
      "                     weighted avg       0.68      0.65      0.65        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 17:30:15,938] Trial 0 finished with value: 0.65 and parameters: {'n_estimators': 60, 'max_depth': 10}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:30:19,310] Trial 1 finished with value: 0.675 and parameters: {'n_estimators': 173, 'max_depth': 10}. Best is trial 1 with value: 0.675.\n",
      "[I 2025-05-27 17:30:21,181] Trial 2 finished with value: 0.65 and parameters: {'n_estimators': 72, 'max_depth': 10}. Best is trial 1 with value: 0.675.\n",
      "[I 2025-05-27 17:30:22,414] Trial 3 finished with value: 0.625 and parameters: {'n_estimators': 54, 'max_depth': 10}. Best is trial 1 with value: 0.675.\n",
      "[I 2025-05-27 17:30:24,151] Trial 4 finished with value: 0.65 and parameters: {'n_estimators': 63, 'max_depth': 20}. Best is trial 1 with value: 0.675.\n",
      "[I 2025-05-27 17:30:26,702] Trial 5 finished with value: 0.6 and parameters: {'n_estimators': 105, 'max_depth': 10}. Best is trial 1 with value: 0.675.\n",
      "[I 2025-05-27 17:30:32,235] Trial 6 finished with value: 0.6 and parameters: {'n_estimators': 231, 'max_depth': 20}. Best is trial 1 with value: 0.675.\n",
      "[I 2025-05-27 17:30:34,805] Trial 7 finished with value: 0.7 and parameters: {'n_estimators': 119, 'max_depth': 50}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:30:39,210] Trial 8 finished with value: 0.625 and parameters: {'n_estimators': 213, 'max_depth': 20}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:30:43,489] Trial 9 finished with value: 0.675 and parameters: {'n_estimators': 199, 'max_depth': 30}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:30:46,267] Trial 10 finished with value: 0.7 and parameters: {'n_estimators': 134, 'max_depth': 50}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:30:49,193] Trial 11 finished with value: 0.7 and parameters: {'n_estimators': 145, 'max_depth': 50}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:30:54,816] Trial 12 finished with value: 0.65 and parameters: {'n_estimators': 298, 'max_depth': 50}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:30:57,420] Trial 13 finished with value: 0.7 and parameters: {'n_estimators': 129, 'max_depth': 40}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:30:59,664] Trial 14 finished with value: 0.65 and parameters: {'n_estimators': 111, 'max_depth': 40}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:31:02,812] Trial 15 finished with value: 0.675 and parameters: {'n_estimators': 160, 'max_depth': 40}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:31:04,664] Trial 16 finished with value: 0.65 and parameters: {'n_estimators': 96, 'max_depth': 50}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:31:07,143] Trial 17 finished with value: 0.7 and parameters: {'n_estimators': 133, 'max_depth': 40}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:31:12,185] Trial 18 finished with value: 0.65 and parameters: {'n_estimators': 257, 'max_depth': 50}. Best is trial 7 with value: 0.7.\n",
      "[I 2025-05-27 17:31:15,963] Trial 19 finished with value: 0.675 and parameters: {'n_estimators': 191, 'max_depth': 30}. Best is trial 7 with value: 0.7.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForest Performance (Training _2):\n",
      "Accuracy: 0.7000\n",
      "F1-Score: 0.6726\n",
      "Confusion Matrix:\n",
      "[[ 5  4  0  0  0  1]\n",
      " [ 1 18  0  0  0  1]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  1  0  1  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  2  0  0  0  1]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.83      0.50      0.62        10\n",
      "                            Other       0.67      0.90      0.77        20\n",
      "                     Criminal Law       0.00      0.00      0.00         2\n",
      "Enforcement of Fundamental Rights       1.00      0.50      0.67         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.33      0.33      0.33         3\n",
      "\n",
      "                         accuracy                           0.70        40\n",
      "                        macro avg       0.64      0.54      0.57        40\n",
      "                     weighted avg       0.69      0.70      0.67        40\n",
      "\n",
      "Label Distribution Before Merging (Training _3):\n",
      " Other                                97\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Garnishee Proceedings                 1\n",
      "Civil Law                             1\n",
      "Name: label, dtype: int64\n",
      "Merging rare classes (fewer than 2 instances) for Training _3: ['Garnishee Proceedings', 'Civil Law']\n",
      "Label Distribution After Merging (Training _3):\n",
      " Other                                99\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Train Label Distribution (Training _3):\n",
      " 1    79\n",
      "0    39\n",
      "4    15\n",
      "5    12\n",
      "2     8\n",
      "3     7\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Test Label Distribution (Training _3):\n",
      " 1    20\n",
      "0    10\n",
      "4     3\n",
      "5     3\n",
      "2     2\n",
      "3     2\n",
      "Name: label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 17:31:40,703] A new study created in memory with name: no-name-06d53a4e-a00c-4bd7-a336-4cdd1566bb7c\n",
      "[I 2025-05-27 17:31:42,133] Trial 0 finished with value: 0.65 and parameters: {'C': 2.8758356969522363, 'max_iter': 1175}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:31:42,740] Trial 1 finished with value: 0.65 and parameters: {'C': 0.1427843293417266, 'max_iter': 1007}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:31:43,627] Trial 2 finished with value: 0.65 and parameters: {'C': 0.43849109086442023, 'max_iter': 899}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:31:44,252] Trial 3 finished with value: 0.65 and parameters: {'C': 0.1608102121797931, 'max_iter': 1378}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:31:44,994] Trial 4 finished with value: 0.65 and parameters: {'C': 0.21883038324936716, 'max_iter': 1222}. Best is trial 0 with value: 0.65.\n",
      "[I 2025-05-27 17:31:46,114] Trial 5 finished with value: 0.675 and parameters: {'C': 1.1978239520434402, 'max_iter': 912}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:31:47,671] Trial 6 finished with value: 0.6 and parameters: {'C': 4.201914953634021, 'max_iter': 975}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:31:48,916] Trial 7 finished with value: 0.65 and parameters: {'C': 1.6136714077202725, 'max_iter': 1045}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:31:50,568] Trial 8 finished with value: 0.6 and parameters: {'C': 5.449777347346191, 'max_iter': 780}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:31:51,474] Trial 9 finished with value: 0.65 and parameters: {'C': 0.49127174693420433, 'max_iter': 590}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:31:52,595] Trial 10 finished with value: 0.675 and parameters: {'C': 1.1327352793396013, 'max_iter': 515}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:31:53,769] Trial 11 finished with value: 0.675 and parameters: {'C': 1.0160178145896803, 'max_iter': 504}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:31:54,978] Trial 12 finished with value: 0.65 and parameters: {'C': 1.6239198127943384, 'max_iter': 683}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:31:55,895] Trial 13 finished with value: 0.65 and parameters: {'C': 0.47277095377361633, 'max_iter': 757}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:31:57,822] Trial 14 finished with value: 0.6 and parameters: {'C': 8.735531930533785, 'max_iter': 834}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:31:58,886] Trial 15 finished with value: 0.675 and parameters: {'C': 0.8471647281710699, 'max_iter': 633}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:32:00,497] Trial 16 finished with value: 0.65 and parameters: {'C': 2.2618483078706797, 'max_iter': 1431}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:32:01,650] Trial 17 finished with value: 0.675 and parameters: {'C': 0.8981130514139902, 'max_iter': 1174}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:32:02,376] Trial 18 finished with value: 0.65 and parameters: {'C': 0.29599680501234615, 'max_iter': 536}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:32:03,578] Trial 19 finished with value: 0.675 and parameters: {'C': 1.2840950622190277, 'max_iter': 707}. Best is trial 5 with value: 0.675.\n",
      "[I 2025-05-27 17:32:04,714] A new study created in memory with name: no-name-424816c6-cb14-43cb-b0cb-2920fdf4341d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LogisticRegression Performance (Training _3):\n",
      "Accuracy: 0.6750\n",
      "F1-Score: 0.6755\n",
      "Confusion Matrix:\n",
      "[[ 8  2  0  0  0  0]\n",
      " [ 7 11  0  0  0  2]\n",
      " [ 0  1  1  0  0  0]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  1  0  0  0  2]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.53      0.80      0.64        10\n",
      "                            Other       0.73      0.55      0.63        20\n",
      "                     Criminal Law       1.00      0.50      0.67         2\n",
      "Enforcement of Fundamental Rights       1.00      1.00      1.00         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.50      0.67      0.57         3\n",
      "\n",
      "                         accuracy                           0.68        40\n",
      "                        macro avg       0.79      0.75      0.75        40\n",
      "                     weighted avg       0.71      0.68      0.68        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 17:32:12,377] Trial 0 finished with value: 0.6 and parameters: {'C': 0.12230028364670077, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:32:16,212] Trial 1 finished with value: 0.55 and parameters: {'C': 0.9404556228757738, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:32:19,660] Trial 2 finished with value: 0.55 and parameters: {'C': 2.5018552422132534, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:32:24,074] Trial 3 finished with value: 0.525 and parameters: {'C': 0.5338646314717985, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:32:29,635] Trial 4 finished with value: 0.575 and parameters: {'C': 0.3206445014490169, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:32:35,748] Trial 5 finished with value: 0.55 and parameters: {'C': 0.16023252763237578, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:32:39,211] Trial 6 finished with value: 0.55 and parameters: {'C': 5.5409544330388325, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:32:42,747] Trial 7 finished with value: 0.55 and parameters: {'C': 4.819363403041286, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:32:46,551] Trial 8 finished with value: 0.55 and parameters: {'C': 2.3142640989227776, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:32:51,702] Trial 9 finished with value: 0.575 and parameters: {'C': 0.43906469380765645, 'kernel': 'rbf'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:33:00,149] Trial 10 finished with value: 0.6 and parameters: {'C': 0.10017610783063292, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:33:07,212] Trial 11 finished with value: 0.6 and parameters: {'C': 0.11938407931299501, 'kernel': 'linear'}. Best is trial 0 with value: 0.6.\n",
      "[I 2025-05-27 17:33:13,175] Trial 12 finished with value: 0.65 and parameters: {'C': 0.20390857278140392, 'kernel': 'linear'}. Best is trial 12 with value: 0.65.\n",
      "[I 2025-05-27 17:33:18,899] Trial 13 finished with value: 0.65 and parameters: {'C': 0.23314460058221792, 'kernel': 'linear'}. Best is trial 12 with value: 0.65.\n",
      "[I 2025-05-27 17:33:24,500] Trial 14 finished with value: 0.65 and parameters: {'C': 0.2474218991785612, 'kernel': 'linear'}. Best is trial 12 with value: 0.65.\n",
      "[I 2025-05-27 17:33:28,885] Trial 15 finished with value: 0.65 and parameters: {'C': 0.815166498836566, 'kernel': 'linear'}. Best is trial 12 with value: 0.65.\n",
      "[I 2025-05-27 17:33:34,667] Trial 16 finished with value: 0.625 and parameters: {'C': 0.26818140310378136, 'kernel': 'linear'}. Best is trial 12 with value: 0.65.\n",
      "[I 2025-05-27 17:33:37,912] Trial 17 finished with value: 0.6 and parameters: {'C': 1.5514357969967512, 'kernel': 'linear'}. Best is trial 12 with value: 0.65.\n",
      "[I 2025-05-27 17:33:44,020] Trial 18 finished with value: 0.65 and parameters: {'C': 0.19738401575344125, 'kernel': 'linear'}. Best is trial 12 with value: 0.65.\n",
      "[I 2025-05-27 17:33:48,378] Trial 19 finished with value: 0.625 and parameters: {'C': 0.5244902906646758, 'kernel': 'linear'}. Best is trial 12 with value: 0.65.\n",
      "[I 2025-05-27 17:33:54,454] A new study created in memory with name: no-name-afa988a7-53e3-42ae-82ac-c0148e01aac3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SVM Performance (Training _3):\n",
      "Accuracy: 0.6500\n",
      "F1-Score: 0.6527\n",
      "Confusion Matrix:\n",
      "[[ 8  1  0  0  0  1]\n",
      " [ 8 10  0  0  0  2]\n",
      " [ 0  1  1  0  0  0]\n",
      " [ 0  0  0  2  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  1  0  0  0  2]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.50      0.80      0.62        10\n",
      "                            Other       0.77      0.50      0.61        20\n",
      "                     Criminal Law       1.00      0.50      0.67         2\n",
      "Enforcement of Fundamental Rights       1.00      1.00      1.00         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.40      0.67      0.50         3\n",
      "\n",
      "                         accuracy                           0.65        40\n",
      "                        macro avg       0.78      0.74      0.73        40\n",
      "                     weighted avg       0.71      0.65      0.65        40\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-27 17:33:55,995] Trial 0 finished with value: 0.55 and parameters: {'n_estimators': 80, 'max_depth': 20}. Best is trial 0 with value: 0.55.\n",
      "[I 2025-05-27 17:34:01,656] Trial 1 finished with value: 0.625 and parameters: {'n_estimators': 290, 'max_depth': 40}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:03,558] Trial 2 finished with value: 0.575 and parameters: {'n_estimators': 103, 'max_depth': 20}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:06,550] Trial 3 finished with value: 0.55 and parameters: {'n_estimators': 156, 'max_depth': 50}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:12,000] Trial 4 finished with value: 0.625 and parameters: {'n_estimators': 300, 'max_depth': 20}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:14,772] Trial 5 finished with value: 0.575 and parameters: {'n_estimators': 145, 'max_depth': 30}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:19,522] Trial 6 finished with value: 0.625 and parameters: {'n_estimators': 271, 'max_depth': 10}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:23,017] Trial 7 finished with value: 0.575 and parameters: {'n_estimators': 207, 'max_depth': 10}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:24,491] Trial 8 finished with value: 0.5 and parameters: {'n_estimators': 77, 'max_depth': 10}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:25,955] Trial 9 finished with value: 0.55 and parameters: {'n_estimators': 78, 'max_depth': 20}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:30,561] Trial 10 finished with value: 0.55 and parameters: {'n_estimators': 228, 'max_depth': 50}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:37,336] Trial 11 finished with value: 0.625 and parameters: {'n_estimators': 300, 'max_depth': 40}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:42,424] Trial 12 finished with value: 0.625 and parameters: {'n_estimators': 256, 'max_depth': 40}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:47,778] Trial 13 finished with value: 0.575 and parameters: {'n_estimators': 297, 'max_depth': 30}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:51,412] Trial 14 finished with value: 0.55 and parameters: {'n_estimators': 214, 'max_depth': 40}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:55,818] Trial 15 finished with value: 0.6 and parameters: {'n_estimators': 252, 'max_depth': 30}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:34:59,723] Trial 16 finished with value: 0.5 and parameters: {'n_estimators': 182, 'max_depth': 40}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:35:04,962] Trial 17 finished with value: 0.6 and parameters: {'n_estimators': 271, 'max_depth': 20}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:35:09,235] Trial 18 finished with value: 0.55 and parameters: {'n_estimators': 238, 'max_depth': 30}. Best is trial 1 with value: 0.625.\n",
      "[I 2025-05-27 17:35:14,206] Trial 19 finished with value: 0.6 and parameters: {'n_estimators': 278, 'max_depth': 50}. Best is trial 1 with value: 0.625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RandomForest Performance (Training _3):\n",
      "Accuracy: 0.6250\n",
      "F1-Score: 0.5875\n",
      "Confusion Matrix:\n",
      "[[ 3  6  0  0  0  1]\n",
      " [ 2 17  0  0  0  1]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  1  0  1  0  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  2  0  0  0  1]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.60      0.30      0.40        10\n",
      "                            Other       0.61      0.85      0.71        20\n",
      "                     Criminal Law       0.00      0.00      0.00         2\n",
      "Enforcement of Fundamental Rights       1.00      0.50      0.67         2\n",
      "                Election Petition       1.00      1.00      1.00         3\n",
      "                     Property Law       0.33      0.33      0.33         3\n",
      "\n",
      "                         accuracy                           0.62        40\n",
      "                        macro avg       0.59      0.50      0.52        40\n",
      "                     weighted avg       0.60      0.62      0.59        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training 1: Baseline (no balancing, no augmentation)\n",
    "models_1, vectorizer_1, model_accuracies_1, X_test_tfidf_1, y_test_1, label_map_1 = run_lr_svm_rf_training(df, '_1')\n",
    "\n",
    "# Training 2: Balanced, no augmentation\n",
    "models_2, vectorizer_2, model_accuracies_2, X_test_tfidf_2, y_test_2, label_map_2 = run_lr_svm_rf_training(df, '_2', balance=True)\n",
    "\n",
    "# Training 3: Balanced + Augmented (advanced)\n",
    "models_3, vectorizer_3, model_accuracies_3, X_test_tfidf_3, y_test_3, label_map_3 = run_lr_svm_rf_training(df, '_3', balance=True, augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling - BERT (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_title</th>\n",
       "      <th>suitno</th>\n",
       "      <th>introduction</th>\n",
       "      <th>facts</th>\n",
       "      <th>issues</th>\n",
       "      <th>decision</th>\n",
       "      <th>full_report</th>\n",
       "      <th>full_report_cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASSET MANAGEMENT GROUP LIMITED v. GENESISCORP ...</td>\n",
       "      <td>CA/L/236M/95</td>\n",
       "      <td>This appeal borders on Civil Procedure.\\n</td>\n",
       "      <td>The appellant as Plaintiff before the Lagos Hi...</td>\n",
       "      <td>The Appellant formulated the following issues ...</td>\n",
       "      <td>On the whole, the Court of Appeal held that th...</td>\n",
       "      <td>GEORGE ADESOLA&amp;nbsp;OGUNTADE, J.C.A. (Deliveri...</td>\n",
       "      <td>george adesola oguntade j c a delivering the l...</td>\n",
       "      <td>Civil Procedure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JAMES EBELE &amp; ANOR v. ROBERT IKWEKI &amp; ORS</td>\n",
       "      <td>CA/B/53M/2006</td>\n",
       "      <td>This is a ruling on an Application seeking Lea...</td>\n",
       "      <td>The present application flows from the Judgmen...</td>\n",
       "      <td>The Court determined the proprietary or otherw...</td>\n",
       "      <td>In the final analysis, the Court of Appeal hel...</td>\n",
       "      <td>\\nCHIOMA EGONDU NWOSU-IHEME&amp;nbsp;J.C.A.  (Deli...</td>\n",
       "      <td>chioma egondu nwosu iheme j c a delivering the...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CENTRAL BANK OF NIGERIA v. MR TOMMY OKECHUKWU ...</td>\n",
       "      <td>CA/K/304/2020</td>\n",
       "      <td>This appeal borders on propriety of requiremen...</td>\n",
       "      <td>This appeal emanated from the decision of the ...</td>\n",
       "      <td>The Court of Appeal determined the appeal base...</td>\n",
       "      <td>In the end, the Court of Appeal resolved the s...</td>\n",
       "      <td>PETER OYINKENIMIEMI AFFEN, J.C.A. (Delivering ...</td>\n",
       "      <td>peter oyinkenimiemi affen j c a delivering the...</td>\n",
       "      <td>Garnishee Proceedings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MOHAMMED AUWAL &amp; ORS v. THE FEDERAL REPUBLIC O...</td>\n",
       "      <td>CA/J/183C/2011</td>\n",
       "      <td>This appeal borders on Criminal Law and Proced...</td>\n",
       "      <td>This appeal is against the judgment of the Fed...</td>\n",
       "      <td>The Court determined the appeal on the followi...</td>\n",
       "      <td>In conclusion, the appeal was dismissed.\\n</td>\n",
       "      <td>IBRAHIM SHATA BDLIYA, J.C.A. (Deliveringthe Le...</td>\n",
       "      <td>ibrahim shata bdliya j c a deliveringthe leadi...</td>\n",
       "      <td>Criminal Law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNITED BANK FOR AFRICA PLC &amp; ORS v. MR. UGOCHU...</td>\n",
       "      <td>CA/OW/385M/2012</td>\n",
       "      <td>This appeal borders on Enforcement of Fundamen...</td>\n",
       "      <td>This is an appeal against the judgment of NGOZ...</td>\n",
       "      <td>Appellant formulated 4 issues while the Respon...</td>\n",
       "      <td>On the whole, the Court found no merit in the ...</td>\n",
       "      <td>FREDERICK OZIAKPONO&amp;nbsp;OHO, J.C.A. (Deliveri...</td>\n",
       "      <td>frederick oziakpono oho j c a delivering the l...</td>\n",
       "      <td>Enforcement of Fundamental Rights</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          case_title           suitno  \\\n",
       "0  ASSET MANAGEMENT GROUP LIMITED v. GENESISCORP ...     CA/L/236M/95   \n",
       "1          JAMES EBELE & ANOR v. ROBERT IKWEKI & ORS    CA/B/53M/2006   \n",
       "2  CENTRAL BANK OF NIGERIA v. MR TOMMY OKECHUKWU ...    CA/K/304/2020   \n",
       "3  MOHAMMED AUWAL & ORS v. THE FEDERAL REPUBLIC O...   CA/J/183C/2011   \n",
       "4  UNITED BANK FOR AFRICA PLC & ORS v. MR. UGOCHU...  CA/OW/385M/2012   \n",
       "\n",
       "                                        introduction  \\\n",
       "0          This appeal borders on Civil Procedure.\\n   \n",
       "1  This is a ruling on an Application seeking Lea...   \n",
       "2  This appeal borders on propriety of requiremen...   \n",
       "3  This appeal borders on Criminal Law and Proced...   \n",
       "4  This appeal borders on Enforcement of Fundamen...   \n",
       "\n",
       "                                               facts  \\\n",
       "0  The appellant as Plaintiff before the Lagos Hi...   \n",
       "1  The present application flows from the Judgmen...   \n",
       "2  This appeal emanated from the decision of the ...   \n",
       "3  This appeal is against the judgment of the Fed...   \n",
       "4  This is an appeal against the judgment of NGOZ...   \n",
       "\n",
       "                                              issues  \\\n",
       "0  The Appellant formulated the following issues ...   \n",
       "1  The Court determined the proprietary or otherw...   \n",
       "2  The Court of Appeal determined the appeal base...   \n",
       "3  The Court determined the appeal on the followi...   \n",
       "4  Appellant formulated 4 issues while the Respon...   \n",
       "\n",
       "                                            decision  \\\n",
       "0  On the whole, the Court of Appeal held that th...   \n",
       "1  In the final analysis, the Court of Appeal hel...   \n",
       "2  In the end, the Court of Appeal resolved the s...   \n",
       "3         In conclusion, the appeal was dismissed.\\n   \n",
       "4  On the whole, the Court found no merit in the ...   \n",
       "\n",
       "                                         full_report  \\\n",
       "0  GEORGE ADESOLA&nbsp;OGUNTADE, J.C.A. (Deliveri...   \n",
       "1  \\nCHIOMA EGONDU NWOSU-IHEME&nbsp;J.C.A.  (Deli...   \n",
       "2  PETER OYINKENIMIEMI AFFEN, J.C.A. (Delivering ...   \n",
       "3  IBRAHIM SHATA BDLIYA, J.C.A. (Deliveringthe Le...   \n",
       "4  FREDERICK OZIAKPONO&nbsp;OHO, J.C.A. (Deliveri...   \n",
       "\n",
       "                                 full_report_cleaned  \\\n",
       "0  george adesola oguntade j c a delivering the l...   \n",
       "1  chioma egondu nwosu iheme j c a delivering the...   \n",
       "2  peter oyinkenimiemi affen j c a delivering the...   \n",
       "3  ibrahim shata bdliya j c a deliveringthe leadi...   \n",
       "4  frederick oziakpono oho j c a delivering the l...   \n",
       "\n",
       "                               label  \n",
       "0                    Civil Procedure  \n",
       "1                              Other  \n",
       "2              Garnishee Proceedings  \n",
       "3                       Criminal Law  \n",
       "4  Enforcement of Fundamental Rights  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution Before Merging (Training 1):\n",
      " Other                                97\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Garnishee Proceedings                 1\n",
      "Civil Law                             1\n",
      "Name: label, dtype: int64\n",
      "Merging rare classes (fewer than 2 instances) for Training 1: ['Garnishee Proceedings', 'Civil Law']\n",
      "Label Distribution After Merging (Training 1):\n",
      " Other                                99\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Train Label Distribution (Training 1):\n",
      " 4    79\n",
      "0    39\n",
      "2    15\n",
      "5    12\n",
      "1     8\n",
      "3     7\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Test Label Distribution (Training 1):\n",
      " 4    20\n",
      "0    10\n",
      "2     3\n",
      "5     3\n",
      "1     2\n",
      "3     2\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for first training\n",
    "X = df['full_report_cleaned']\n",
    "y = df['label']\n",
    "\n",
    "# Check label distribution and merge rare classes (fewer than 2 instances)\n",
    "label_counts_1 = y.value_counts()\n",
    "print(\"Label Distribution Before Merging (Training 1):\\n\", label_counts_1)\n",
    "\n",
    "# Identify classes with fewer than 2 instances\n",
    "rare_classes_1 = label_counts_1[label_counts_1 < 2].index\n",
    "if len(rare_classes_1) > 0:\n",
    "    print(f\"Merging rare classes (fewer than 2 instances) for Training 1: {list(rare_classes_1)}\")\n",
    "    y_merged_1 = y.copy()\n",
    "    y_merged_1[y_merged_1.isin(rare_classes_1)] = 'Other'\n",
    "else:\n",
    "    print(\"No rare classes found for Training 1.\")\n",
    "    y_merged_1 = y\n",
    "\n",
    "# Verify new distribution\n",
    "print(\"Label Distribution After Merging (Training 1):\\n\", y_merged_1.value_counts())\n",
    "\n",
    "# Encode labels after merging\n",
    "labels_sorted = sorted(y_merged_1.unique())\n",
    "label_map_1 = {label: idx for idx, label in enumerate(labels_sorted)}\n",
    "y_encoded_1 = y_merged_1.map(label_map_1)\n",
    "\n",
    "# Extract text data\n",
    "X_1 = df['full_report_cleaned']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(\n",
    "    X_1, y_encoded_1, test_size=0.2, random_state=42, stratify=y_encoded_1\n",
    ")\n",
    "\n",
    "# Reset index to prevent alignment issues\n",
    "X_train_1 = X_train_1.reset_index(drop=True)\n",
    "X_test_1 = X_test_1.reset_index(drop=True)\n",
    "y_train_1 = y_train_1.reset_index(drop=True)\n",
    "y_test_1 = y_test_1.reset_index(drop=True)\n",
    "\n",
    "# Verify split distributions\n",
    "print(\"\\nTrain Label Distribution (Training 1):\\n\", y_train_1.value_counts())\n",
    "print(\"\\nTest Label Distribution (Training 1):\\n\", y_test_1.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer with reduced max_length for first training\n",
    "tokenizer_1 = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function_1(texts, max_length=512):\n",
    "    \"\"\"Tokenize text for BERT with padding and truncation (Training 1).\"\"\"\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.tolist()\n",
    "    return tokenizer_1(\n",
    "        texts,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "class LegalDataset_1(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.encodings = tokenize_function_1(texts)\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# Prepare datasets for first training\n",
    "train_dataset_1 = LegalDataset_1(X_train_1, y_train_1)\n",
    "test_dataset_1 = LegalDataset_1(X_test_1, y_test_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT model with class weights for first training\n",
    "num_labels_1 = len(label_map_1)\n",
    "bert_model_1 = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments for first training\n",
    "training_args_1 = TrainingArguments(\n",
    "    output_dir='./results_1',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs_1',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    "    learning_rate=2e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights correctly for first training\n",
    "class_counts_1 = np.bincount(y_train_1)\n",
    "total_samples_1 = len(y_train_1)\n",
    "num_labels_1 = len(label_map_1)\n",
    "class_weights_1 = torch.tensor([total_samples_1 / (num_labels_1 * count) if count > 0 else 1.0 for count in class_counts_1], dtype=torch.float)\n",
    "\n",
    "# Custom trainer with class weights for first training\n",
    "class WeightedTrainer_1(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get('labels')\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_1.to(logits.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "trainer_1 = WeightedTrainer_1(\n",
    "    model=bert_model_1,\n",
    "    args=training_args_1,\n",
    "    train_dataset=train_dataset_1,\n",
    "    eval_dataset=test_dataset_1,\n",
    "    compute_metrics=lambda eval_pred: {\n",
    "        'accuracy': accuracy_score(eval_pred.label_ids, np.argmax(eval_pred.predictions, axis=1)),\n",
    "        'f1': f1_score(eval_pred.label_ids, np.argmax(eval_pred.predictions, axis=1), average='weighted')\n",
    "    }\n",
    ")\n",
    "trainer_1.create_optimizer_and_scheduler(num_training_steps=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5601facb684828a4ba9dbf4ca9c4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/800 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8315, 'learning_rate': 4.0000000000000003e-07, 'epoch': 0.12}\n",
      "{'loss': 2.0891, 'learning_rate': 8.000000000000001e-07, 'epoch': 0.25}\n",
      "{'loss': 1.9897, 'learning_rate': 1.2000000000000002e-06, 'epoch': 0.38}\n",
      "{'loss': 2.0687, 'learning_rate': 1.6000000000000001e-06, 'epoch': 0.5}\n",
      "{'loss': 2.1006, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.62}\n",
      "{'loss': 1.9925, 'learning_rate': 2.4000000000000003e-06, 'epoch': 0.75}\n",
      "{'loss': 2.1197, 'learning_rate': 2.8000000000000003e-06, 'epoch': 0.88}\n",
      "{'loss': 2.0089, 'learning_rate': 3.2000000000000003e-06, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a773fd7a624425a9af9459be85ac1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.029087781906128, 'eval_accuracy': 0.1, 'eval_f1': 0.03625, 'eval_runtime': 12.8764, 'eval_samples_per_second': 3.106, 'eval_steps_per_second': 1.553, 'epoch': 1.0}\n",
      "{'loss': 2.0148, 'learning_rate': 3.6000000000000003e-06, 'epoch': 1.12}\n",
      "{'loss': 2.0407, 'learning_rate': 4.000000000000001e-06, 'epoch': 1.25}\n",
      "{'loss': 1.9733, 'learning_rate': 4.4e-06, 'epoch': 1.38}\n",
      "{'loss': 2.0178, 'learning_rate': 4.800000000000001e-06, 'epoch': 1.5}\n",
      "{'loss': 2.0779, 'learning_rate': 5.2e-06, 'epoch': 1.62}\n",
      "{'loss': 1.9005, 'learning_rate': 5.600000000000001e-06, 'epoch': 1.75}\n",
      "{'loss': 1.9874, 'learning_rate': 6e-06, 'epoch': 1.88}\n",
      "{'loss': 2.057, 'learning_rate': 6.4000000000000006e-06, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dffb3275bd245c0b0abac9d539f50ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0097861289978027, 'eval_accuracy': 0.1, 'eval_f1': 0.032967032967032975, 'eval_runtime': 10.4497, 'eval_samples_per_second': 3.828, 'eval_steps_per_second': 1.914, 'epoch': 2.0}\n",
      "{'loss': 2.1631, 'learning_rate': 6.800000000000001e-06, 'epoch': 2.12}\n",
      "{'loss': 1.9998, 'learning_rate': 7.2000000000000005e-06, 'epoch': 2.25}\n",
      "{'loss': 1.9662, 'learning_rate': 7.600000000000001e-06, 'epoch': 2.38}\n",
      "{'loss': 2.0334, 'learning_rate': 8.000000000000001e-06, 'epoch': 2.5}\n",
      "{'loss': 1.9725, 'learning_rate': 8.400000000000001e-06, 'epoch': 2.62}\n",
      "{'loss': 1.901, 'learning_rate': 8.8e-06, 'epoch': 2.75}\n",
      "{'loss': 1.8788, 'learning_rate': 9.200000000000002e-06, 'epoch': 2.88}\n",
      "{'loss': 2.0591, 'learning_rate': 9.600000000000001e-06, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924516e045a543d385986e23b45dfdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9763389825820923, 'eval_accuracy': 0.1, 'eval_f1': 0.0305921052631579, 'eval_runtime': 9.7507, 'eval_samples_per_second': 4.102, 'eval_steps_per_second': 2.051, 'epoch': 3.0}\n",
      "{'loss': 2.0679, 'learning_rate': 1e-05, 'epoch': 3.12}\n",
      "{'loss': 1.9019, 'learning_rate': 1.04e-05, 'epoch': 3.25}\n",
      "{'loss': 1.9659, 'learning_rate': 1.0800000000000002e-05, 'epoch': 3.38}\n",
      "{'loss': 1.9612, 'learning_rate': 1.1200000000000001e-05, 'epoch': 3.5}\n",
      "{'loss': 2.0037, 'learning_rate': 1.16e-05, 'epoch': 3.62}\n",
      "{'loss': 1.9644, 'learning_rate': 1.2e-05, 'epoch': 3.75}\n",
      "{'loss': 1.9704, 'learning_rate': 1.2400000000000002e-05, 'epoch': 3.88}\n",
      "{'loss': 1.8419, 'learning_rate': 1.2800000000000001e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19eddd137ba4fbf84f3955bc386ed4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9091078042984009, 'eval_accuracy': 0.1, 'eval_f1': 0.026493506493506493, 'eval_runtime': 10.6167, 'eval_samples_per_second': 3.768, 'eval_steps_per_second': 1.884, 'epoch': 4.0}\n",
      "{'loss': 1.906, 'learning_rate': 1.3200000000000002e-05, 'epoch': 4.12}\n",
      "{'loss': 2.0227, 'learning_rate': 1.3600000000000002e-05, 'epoch': 4.25}\n",
      "{'loss': 1.9768, 'learning_rate': 1.4e-05, 'epoch': 4.38}\n",
      "{'loss': 1.8118, 'learning_rate': 1.4400000000000001e-05, 'epoch': 4.5}\n",
      "{'loss': 1.8625, 'learning_rate': 1.48e-05, 'epoch': 4.62}\n",
      "{'loss': 1.8183, 'learning_rate': 1.5200000000000002e-05, 'epoch': 4.75}\n",
      "{'loss': 1.8124, 'learning_rate': 1.5600000000000003e-05, 'epoch': 4.88}\n",
      "{'loss': 1.8298, 'learning_rate': 1.6000000000000003e-05, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3d2627d48e45f796b49eae2ce34565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8181520700454712, 'eval_accuracy': 0.075, 'eval_f1': 0.011538461538461539, 'eval_runtime': 14.7728, 'eval_samples_per_second': 2.708, 'eval_steps_per_second': 1.354, 'epoch': 5.0}\n",
      "{'loss': 1.8194, 'learning_rate': 1.64e-05, 'epoch': 5.12}\n",
      "{'loss': 1.7659, 'learning_rate': 1.6800000000000002e-05, 'epoch': 5.25}\n",
      "{'loss': 1.8686, 'learning_rate': 1.72e-05, 'epoch': 5.38}\n",
      "{'loss': 1.7734, 'learning_rate': 1.76e-05, 'epoch': 5.5}\n",
      "{'loss': 1.779, 'learning_rate': 1.8e-05, 'epoch': 5.62}\n",
      "{'loss': 1.7445, 'learning_rate': 1.8400000000000003e-05, 'epoch': 5.75}\n",
      "{'loss': 1.8133, 'learning_rate': 1.88e-05, 'epoch': 5.88}\n",
      "{'loss': 1.8218, 'learning_rate': 1.9200000000000003e-05, 'epoch': 6.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c4c582ea1b249ceaf355ab39b198acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7439228296279907, 'eval_accuracy': 0.325, 'eval_f1': 0.30302197802197806, 'eval_runtime': 9.7879, 'eval_samples_per_second': 4.087, 'eval_steps_per_second': 2.043, 'epoch': 6.0}\n",
      "{'loss': 1.6658, 'learning_rate': 1.9600000000000002e-05, 'epoch': 6.12}\n",
      "{'loss': 1.7404, 'learning_rate': 2e-05, 'epoch': 6.25}\n",
      "{'loss': 1.7752, 'learning_rate': 1.9333333333333333e-05, 'epoch': 6.38}\n",
      "{'loss': 1.7415, 'learning_rate': 1.866666666666667e-05, 'epoch': 6.5}\n",
      "{'loss': 1.7442, 'learning_rate': 1.8e-05, 'epoch': 6.62}\n",
      "{'loss': 1.854, 'learning_rate': 1.7333333333333336e-05, 'epoch': 6.75}\n",
      "{'loss': 1.7327, 'learning_rate': 1.6666666666666667e-05, 'epoch': 6.88}\n",
      "{'loss': 1.6716, 'learning_rate': 1.6000000000000003e-05, 'epoch': 7.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e773fcd386af40719f628697405dca2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7003593444824219, 'eval_accuracy': 0.375, 'eval_f1': 0.29411764705882354, 'eval_runtime': 15.3984, 'eval_samples_per_second': 2.598, 'eval_steps_per_second': 1.299, 'epoch': 7.0}\n",
      "{'loss': 1.7105, 'learning_rate': 1.5333333333333334e-05, 'epoch': 7.12}\n",
      "{'loss': 1.7543, 'learning_rate': 1.4666666666666666e-05, 'epoch': 7.25}\n",
      "{'loss': 1.715, 'learning_rate': 1.4e-05, 'epoch': 7.38}\n",
      "{'loss': 1.7311, 'learning_rate': 1.3333333333333333e-05, 'epoch': 7.5}\n",
      "{'loss': 1.6708, 'learning_rate': 1.2666666666666667e-05, 'epoch': 7.62}\n",
      "{'loss': 1.8278, 'learning_rate': 1.2e-05, 'epoch': 7.75}\n",
      "{'loss': 1.6091, 'learning_rate': 1.1333333333333334e-05, 'epoch': 7.88}\n",
      "{'loss': 1.7407, 'learning_rate': 1.0666666666666667e-05, 'epoch': 8.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81dade4c4d6497b9bb484b50c26498c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6998875141143799, 'eval_accuracy': 0.5, 'eval_f1': 0.3389830508474576, 'eval_runtime': 10.7236, 'eval_samples_per_second': 3.73, 'eval_steps_per_second': 1.865, 'epoch': 8.0}\n",
      "{'loss': 1.6438, 'learning_rate': 1e-05, 'epoch': 8.12}\n",
      "{'loss': 1.6373, 'learning_rate': 9.333333333333334e-06, 'epoch': 8.25}\n",
      "{'loss': 1.6704, 'learning_rate': 8.666666666666668e-06, 'epoch': 8.38}\n",
      "{'loss': 1.7468, 'learning_rate': 8.000000000000001e-06, 'epoch': 8.5}\n",
      "{'loss': 1.6034, 'learning_rate': 7.333333333333333e-06, 'epoch': 8.62}\n",
      "{'loss': 1.7866, 'learning_rate': 6.666666666666667e-06, 'epoch': 8.75}\n",
      "{'loss': 1.6782, 'learning_rate': 6e-06, 'epoch': 8.88}\n",
      "{'loss': 1.6456, 'learning_rate': 5.333333333333334e-06, 'epoch': 9.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeae805483a34aa2b7a83509962bdea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6945174932479858, 'eval_accuracy': 0.5, 'eval_f1': 0.3389830508474576, 'eval_runtime': 9.8052, 'eval_samples_per_second': 4.079, 'eval_steps_per_second': 2.04, 'epoch': 9.0}\n",
      "{'loss': 1.7789, 'learning_rate': 4.666666666666667e-06, 'epoch': 9.12}\n",
      "{'loss': 1.7616, 'learning_rate': 4.000000000000001e-06, 'epoch': 9.25}\n",
      "{'loss': 1.6755, 'learning_rate': 3.3333333333333333e-06, 'epoch': 9.38}\n",
      "{'loss': 1.6576, 'learning_rate': 2.666666666666667e-06, 'epoch': 9.5}\n",
      "{'loss': 1.6559, 'learning_rate': 2.0000000000000003e-06, 'epoch': 9.62}\n",
      "{'loss': 1.5466, 'learning_rate': 1.3333333333333334e-06, 'epoch': 9.75}\n",
      "{'loss': 1.752, 'learning_rate': 6.666666666666667e-07, 'epoch': 9.88}\n",
      "{'loss': 1.7323, 'learning_rate': 0.0, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803d48b5554442ad8880b8a4bd71046d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.693190336227417, 'eval_accuracy': 0.5, 'eval_f1': 0.3333333333333333, 'eval_runtime': 9.0471, 'eval_samples_per_second': 4.421, 'eval_steps_per_second': 2.211, 'epoch': 10.0}\n",
      "{'train_runtime': 3977.6867, 'train_samples_per_second': 0.402, 'train_steps_per_second': 0.201, 'train_loss': 1.8500644218921662, 'epoch': 10.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=800, training_loss=1.8500644218921662, metrics={'train_runtime': 3977.6867, 'train_samples_per_second': 0.402, 'train_steps_per_second': 0.201, 'train_loss': 1.8500644218921662, 'epoch': 10.0})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train BERT model for first training\n",
    "trainer_1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7fc1cef8964c95b52ac1cb57cf7486",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Performance (Training 1):\n",
      "Accuracy: 0.5000\n",
      "F1-Score: 0.3333\n",
      "Confusion Matrix:\n",
      "[[ 0  0  0  0 10  0]\n",
      " [ 0  0  0  0  2  0]\n",
      " [ 0  0  0  0  3  0]\n",
      " [ 0  0  0  0  2  0]\n",
      " [ 0  0  0  0 20  0]\n",
      " [ 0  0  0  0  3  0]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.00      0.00      0.00        10\n",
      "                     Criminal Law       0.00      0.00      0.00         2\n",
      "                Election Petition       0.00      0.00      0.00         3\n",
      "Enforcement of Fundamental Rights       0.00      0.00      0.00         2\n",
      "                            Other       0.50      1.00      0.67        20\n",
      "                     Property Law       0.00      0.00      0.00         3\n",
      "\n",
      "                         accuracy                           0.50        40\n",
      "                        macro avg       0.08      0.17      0.11        40\n",
      "                     weighted avg       0.25      0.50      0.33        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate BERT for first training\n",
    "predictions_1 = trainer_1.predict(test_dataset_1)\n",
    "y_pred_bert_1 = np.argmax(predictions_1.predictions, axis=1)\n",
    "bert_accuracy_1 = accuracy_score(y_test_1, y_pred_bert_1)\n",
    "bert_f1_1 = f1_score(y_test_1, y_pred_bert_1, average='weighted')\n",
    "\n",
    "print('\\nBERT Performance (Training 1):')\n",
    "print(f'Accuracy: {bert_accuracy_1:.4f}')\n",
    "print(f'F1-Score: {bert_f1_1:.4f}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test_1, y_pred_bert_1))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test_1, y_pred_bert_1, target_names=label_map_1.keys(), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation:\n",
    "\n",
    "- The `BERT model` (Accuracy: 0.5000, F1-Score: 0.3448) is underperforming compared to `Logistic Regression` (Accuracy: 0.6500, F1-Score: 0.6560), `SVM` (Accuracy: 0.6250, F1-Score: 0.6252), and `Random Forest` (Accuracy: 0.5750, F1-Score: 0.5455) is not unusual given the context of the dataset, training setup, and BERT's default configuration.\n",
    "\n",
    "#### Analysis of the Issue\n",
    "\n",
    "##### 1. **Dataset Size and Complexity**\n",
    "- **Small Dataset**: The dataset has only 200 samples, with a 80-20 split resulting in 160 training samples and 40 test samples. BERT, being a large pre-trained transformer model with millions of parameters, typically requires a much larger dataset (thousands of samples) to fine-tune effectively on a downstream task like legal document classification.\n",
    "- **Imbalanced Classes**: The distribution (e.g., `Other`: 20, `Civil Procedure`: 10, etc.) shows significant imbalance, which BERT struggles to handle without proper weighting or oversampling, even though I applied SMOTE and class weights.\n",
    "\n",
    "##### 2. **Training Configuration**\n",
    "- **Epochs and Learning Rate**: I trained for 10 epochs with a learning rate of `2e-5`, which starts high and decreases with a linear schedule. The loss decreases over time (from 1.9116 to 1.7058), but the evaluation metrics (accuracy and F1) plateau around 0.5, suggesting underfitting or insufficient learning.\n",
    "- **Batch Size**: A `per_device_train_batch_size=2` and `per_device_eval_batch_size=2` are very small, likely due to hardware limitations (I'm using a macBook Pro 2020 - i9, 32GB). This reduces the model's ability to generalize across batches and can lead to unstable training.\n",
    "- **Warmup Steps**: `warmup_steps=500` is high relative to your dataset size (160 samples, ~80 steps per epoch with batch size 2), which might cause the learning rate to increase too much early on, disrupting initial convergence.\n",
    "\n",
    "##### 3. **Model Initialization and Fine-Tuning**\n",
    "- **Uninitialized Weights**: The warning about uninitialized `classifier.weight` and `classifier.bias` indicates that BERT’s classification head is randomly initialized. Without sufficient training data or epochs, it fails to learn meaningful class boundaries, leading to poor performance (e.g., predicting mostly `Other` as seen in the confusion matrix).\n",
    "- **Pre-trained Model**: `bert-base-uncased` is a general-purpose model not specialized for legal text. It lacks domain-specific knowledge, which could explain its lower performance compared to simpler models that adapt better to your TF-IDF features.\n",
    "\n",
    "##### 4. **Evaluation Metrics**\n",
    "- **Confusion Matrix**: BERT’s confusion matrix shows it predicts `Other` for nearly all samples (20 out of 20 `Other`, 10 out of 10 `Civil Procedure`, etc.), indicating it’s overfitting to the majority class or failing to learn class distinctions.\n",
    "- **F1-Score Drop**: The weighted F1-score of 0.3448 reflects poor performance across minority classes, with precision and recall at 0.00 for most classes except `Other`.\n",
    "\n",
    "##### 5. **Comparison with Traditional Models**\n",
    "- **TF-IDF Advantage**: Logistic Regression, SVM, and Random Forest benefit from TF-IDF features, which are tailored to text data and reduce dimensionality effectively. These models are also less prone to overfitting on small datasets due to fewer parameters.\n",
    "- **BERT’s Complexity**: BERT’s 110M parameters require more data and tuning to outperform simpler models, which is challenging with your current setup.\n",
    "\n",
    "#### Why BERT Underperforms\n",
    "- **Insufficient Data**: 160 training samples are inadequate for fine-tuning BERT, leading to underfitting.\n",
    "- **Overfitting to Majority Class**: The small batch size and high warmup steps may cause BERT to overfit to `Other`, the majority class.\n",
    "- **Suboptimal Hyperparameters**: The learning rate schedule, batch size, and number of epochs may not be optimal for your dataset.\n",
    "- **Domain Mismatch**: `bert-base-uncased` lacks legal domain knowledge, while TF-IDF models capture task-specific patterns better with your limited data.\n",
    "\n",
    "#### Improvements to Boost BERT Performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Distribution Before Merging (Training 2):\n",
      " Other                                97\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Garnishee Proceedings                 1\n",
      "Civil Law                             1\n",
      "Name: label, dtype: int64\n",
      "Merging rare classes (fewer than 2 instances) for Training 2: ['Garnishee Proceedings', 'Civil Law']\n",
      "Label Distribution After Merging (Training 2):\n",
      " Other                                99\n",
      "Civil Procedure                      49\n",
      "Election Petition                    18\n",
      "Property Law                         15\n",
      "Criminal Law                         10\n",
      "Enforcement of Fundamental Rights     9\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Train Label Distribution (Training 2):\n",
      " 4    79\n",
      "0    39\n",
      "2    15\n",
      "5    12\n",
      "1     8\n",
      "3     7\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Test Label Distribution (Training 2):\n",
      " 4    20\n",
      "0    10\n",
      "2     3\n",
      "5     3\n",
      "1     2\n",
      "3     2\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for second training\n",
    "X = df['full_report_cleaned']\n",
    "y = df['label']\n",
    "\n",
    "# Check label distribution and merge rare classes (fewer than 2 instances)\n",
    "label_counts_2 = y.value_counts()\n",
    "print(\"Label Distribution Before Merging (Training 2):\\n\", label_counts_2)\n",
    "\n",
    "# Identify classes with fewer than 2 instances\n",
    "rare_classes_2 = label_counts_2[label_counts_2 < 2].index\n",
    "if len(rare_classes_2) > 0:\n",
    "    print(f\"Merging rare classes (fewer than 2 instances) for Training 2: {list(rare_classes_2)}\")\n",
    "    y_merged_2 = y.copy()\n",
    "    y_merged_2[y_merged_2.isin(rare_classes_2)] = 'Other'\n",
    "else:\n",
    "    print(\"No rare classes found for Training 2.\")\n",
    "    y_merged_2 = y\n",
    "\n",
    "# Verify new distribution\n",
    "print(\"Label Distribution After Merging (Training 2):\\n\", y_merged_2.value_counts())\n",
    "\n",
    "# Encode labels after merging\n",
    "# Encode labels after merging\n",
    "labels_sorted = sorted(y_merged_2.unique())\n",
    "label_map_2 = {label: idx for idx, label in enumerate(labels_sorted)}\n",
    "y_encoded_2 = y_merged_2.map(label_map_2)\n",
    "\n",
    "# Extract text data\n",
    "X_2 = df['full_report_cleaned']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(\n",
    "    X_2, y_encoded_2, test_size=0.2, random_state=42, stratify=y_encoded_2\n",
    ")\n",
    "\n",
    "# Reset index to prevent alignment issues\n",
    "X_train_2 = X_train_2.reset_index(drop=True)\n",
    "X_test_2 = X_test_2.reset_index(drop=True)\n",
    "y_train_2 = y_train_2.reset_index(drop=True)\n",
    "y_test_2 = y_test_2.reset_index(drop=True)\n",
    "\n",
    "# Verify split distributions\n",
    "print(\"\\nTrain Label Distribution (Training 2):\\n\", y_train_2.value_counts())\n",
    "print(\"\\nTest Label Distribution (Training 2):\\n\", y_test_2.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer with reduced max_length for second training\n",
    "tokenizer_2 = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_function_2(texts, max_length=512):\n",
    "    \"\"\"Tokenize text for BERT with padding and truncation (Training 2).\"\"\"\n",
    "    if isinstance(texts, pd.Series):\n",
    "        texts = texts.tolist()\n",
    "    return tokenizer_2(\n",
    "        texts,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "class LegalDataset_2(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, labels, max_length=128):\n",
    "        self.encodings = tokenize_function_2(texts, max_length)\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# Prepare datasets for second training\n",
    "train_dataset_2 = LegalDataset_2(X_train_2, y_train_2, max_length=128)\n",
    "test_dataset_2 = LegalDataset_2(X_test_2, y_test_2, max_length=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Initialize BERT model for second training\n",
    "num_labels_2 = len(label_map_2)\n",
    "bert_model_2 = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=num_labels_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute class weights for second training\n",
    "class_counts_2 = np.bincount(y_train_2)\n",
    "total_samples_2 = len(y_train_2)\n",
    "num_labels_2 = len(label_map_2)\n",
    "class_weights_2 = torch.tensor([total_samples_2 / (num_labels_2 * count) if count > 0 else 1.0 for count in class_counts_2], dtype=torch.float)\n",
    "\n",
    "# Custom trainer with class weights for second training\n",
    "class WeightedTrainer_2(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get('labels')\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_2.to(logits.device))\n",
    "        loss = loss_fct(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments with optimization for second training\n",
    "training_args_2 = TrainingArguments(\n",
    "    output_dir='./results_2',\n",
    "    num_train_epochs=3,  # Reduced from 10\n",
    "    per_device_train_batch_size=4,  # Increased from 2\n",
    "    per_device_eval_batch_size=4,  # Increased from 2\n",
    "    warmup_steps=50,  # Reduced from 500\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs_2',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='eval_loss',\n",
    "    greater_is_better=False,\n",
    "    learning_rate=2e-5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping for second training\n",
    "early_stopping_2 = EarlyStoppingCallback(early_stopping_patience=2)\n",
    "\n",
    "# Initialize trainer for second training\n",
    "trainer_2 = WeightedTrainer_2(\n",
    "    model=bert_model_2,\n",
    "    args=training_args_2,\n",
    "    train_dataset=train_dataset_2,\n",
    "    eval_dataset=test_dataset_2,\n",
    "    callbacks=[early_stopping_2],\n",
    "    compute_metrics=lambda eval_pred: {\n",
    "        'accuracy': accuracy_score(eval_pred.label_ids, np.argmax(eval_pred.predictions, axis=1)),\n",
    "        'f1': f1_score(eval_pred.label_ids, np.argmax(eval_pred.predictions, axis=1), average='weighted')\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83f6e6a118e64815a0100e83134872b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8844, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.25}\n",
      "{'loss': 1.8179, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.5}\n",
      "{'loss': 1.7797, 'learning_rate': 1.2e-05, 'epoch': 0.75}\n",
      "{'loss': 1.879, 'learning_rate': 1.6000000000000003e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573ff2b318f647569be87ffebd6e2a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.817477822303772, 'eval_accuracy': 0.05, 'eval_f1': 0.004878048780487804, 'eval_runtime': 6.6674, 'eval_samples_per_second': 5.999, 'eval_steps_per_second': 1.5, 'epoch': 1.0}\n",
      "{'loss': 1.8336, 'learning_rate': 2e-05, 'epoch': 1.25}\n",
      "{'loss': 1.8484, 'learning_rate': 1.7142857142857142e-05, 'epoch': 1.5}\n",
      "{'loss': 1.848, 'learning_rate': 1.4285714285714287e-05, 'epoch': 1.75}\n",
      "{'loss': 1.7941, 'learning_rate': 1.1428571428571429e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7b00bdfa8d4fa6b6d984e2d33c77b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8077442646026611, 'eval_accuracy': 0.125, 'eval_f1': 0.13040540540540538, 'eval_runtime': 4.5728, 'eval_samples_per_second': 8.747, 'eval_steps_per_second': 2.187, 'epoch': 2.0}\n",
      "{'loss': 1.8518, 'learning_rate': 8.571428571428571e-06, 'epoch': 2.25}\n",
      "{'loss': 1.8113, 'learning_rate': 5.7142857142857145e-06, 'epoch': 2.5}\n",
      "{'loss': 1.8285, 'learning_rate': 2.8571428571428573e-06, 'epoch': 2.75}\n",
      "{'loss': 1.8095, 'learning_rate': 0.0, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116be8ac16044b46aa25fe87ff62af76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8038082122802734, 'eval_accuracy': 0.125, 'eval_f1': 0.13040540540540538, 'eval_runtime': 5.6946, 'eval_samples_per_second': 7.024, 'eval_steps_per_second': 1.756, 'epoch': 3.0}\n",
      "{'train_runtime': 392.6315, 'train_samples_per_second': 1.223, 'train_steps_per_second': 0.306, 'train_loss': 1.8321923732757568, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=1.8321923732757568, metrics={'train_runtime': 392.6315, 'train_samples_per_second': 1.223, 'train_steps_per_second': 0.306, 'train_loss': 1.8321923732757568, 'epoch': 3.0})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train BERT model for second training\n",
    "trainer_2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ab3217a4704494b8b49bfe1271ad53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BERT Performance (Training 2):\n",
      "Accuracy: 0.1250\n",
      "F1-Score: 0.1304\n",
      "Confusion Matrix:\n",
      "[[ 0  9  0  0  1  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 0  3  0  0  0  0]\n",
      " [ 0  2  0  0  0  0]\n",
      " [ 1 16  0  0  3  0]\n",
      " [ 0  3  0  0  0  0]]\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "                  Civil Procedure       0.00      0.00      0.00        10\n",
      "                     Criminal Law       0.06      1.00      0.11         2\n",
      "                Election Petition       0.00      0.00      0.00         3\n",
      "Enforcement of Fundamental Rights       0.00      0.00      0.00         2\n",
      "                            Other       0.75      0.15      0.25        20\n",
      "                     Property Law       0.00      0.00      0.00         3\n",
      "\n",
      "                         accuracy                           0.12        40\n",
      "                        macro avg       0.13      0.19      0.06        40\n",
      "                     weighted avg       0.38      0.12      0.13        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate BERT for second training\n",
    "predictions_2 = trainer_2.predict(test_dataset_2)\n",
    "y_pred_bert_2 = np.argmax(predictions_2.predictions, axis=1)\n",
    "bert_accuracy_2 = accuracy_score(y_test_2, y_pred_bert_2)\n",
    "bert_f1_2 = f1_score(y_test_2, y_pred_bert_2, average='weighted')\n",
    "\n",
    "print('\\nBERT Performance (Training 2):')\n",
    "print(f'Accuracy: {bert_accuracy_2:.4f}')\n",
    "print(f'F1-Score: {bert_f1_2:.4f}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test_2, y_pred_bert_2))\n",
    "unique_labels_2 = np.unique(y_test_2)\n",
    "target_names_2 = [list(label_map_2.keys())[label] for label in unique_labels_2]\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test_2, y_pred_bert_2, labels=unique_labels_2, target_names=target_names_2, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Observation for BERT**\n",
    "\n",
    "#### **Analysis of the Issue**\n",
    "\n",
    "##### 1. **Dataset Size and Complexity**\n",
    "- **Small Dataset**: 200 samples (160 train, 40 test) are insufficient for BERT’s 110M parameters.\n",
    "- **Imbalanced Classes**: Skewed distribution (e.g., `Other`: 20) challenges BERT without strong mitigation.\n",
    "\n",
    "##### 2. **Training Configuration**\n",
    "- **Epochs and Learning Rate**: 10 epochs with `2e-5` and high `warmup_steps=500` lead to underfitting.\n",
    "- **Batch Size**: Small `batch_size=2` due to hardware limits (MacBook Pro 2020) hinders generalization.\n",
    "\n",
    "##### 3. **Model Initialization**\n",
    "- **Uninitialized Head**: Random `classifier` weights fail to learn with limited data.\n",
    "- **Domain Mismatch**: `bert-base-uncased` lacks legal expertise, lagging behind TF-IDF models.\n",
    "\n",
    "##### 4. **Evaluation Metrics**\n",
    "- **Confusion Matrix**: Overfits to `Other`, predicting it for most samples.\n",
    "- **F1-Score**: 0.3448 shows poor minority class performance.\n",
    "\n",
    "##### 5. **Comparison with Traditional Models**\n",
    "- **Complexity**: 110M parameters need more data than TF-IDF models’ simplicity allows.\n",
    "- **Feature Gap**: Raw text struggles vs. TF-IDF’s tailored features.\n",
    "\n",
    "#### **Why BERT Underperforms**\n",
    "- **Data Scarcity**: 160 samples are too few for fine-tuning.\n",
    "- **Overfitting**: Small batches and high warmup disrupt learning.\n",
    "- **Domain Issue**: General model misses legal nuances.\n",
    "\n",
    "#### **Improvements to Boost BERT Performance**\n",
    "- Switch to `roberta-base`, use focal loss, and apply back-translation.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
    "from torch import nn\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        if self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return F_loss.sum()\n",
    "        return F_loss\n",
    "\n",
    "def run_bert_training(df, suffix, balance=False, back_translation=False):\n",
    "    \"\"\"\n",
    "    Run BERT training with specified suffix on CPU.\n",
    "    Args:\n",
    "        df: DataFrame with 'full_report_cleaned' and 'label' columns\n",
    "        suffix: Suffix for variable naming (e.g., '_1', '_2', '_3')\n",
    "        balance: If True, apply class weighting\n",
    "        back_translation: If True, apply back-translation\n",
    "    Returns:\n",
    "        model, tokenizer, accuracy, f1, y_pred, y_test, label_map\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    X_train, X_test, y_train, y_test, label_map = prepare_data(df, suffix, back_translation=back_translation)\n",
    "\n",
    "    # Initialize tokenizer and model\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "    def tokenize_function(texts, max_length=128):  # Reduced to 128 for CPU\n",
    "        return tokenizer(\n",
    "            texts.tolist(),\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "    class LegalDataset(torch.utils.data.Dataset):\n",
    "        def __init__(self, texts, labels):\n",
    "            self.encodings = tokenize_function(texts)\n",
    "            self.labels = labels\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.labels)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "            item['labels'] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "            return item\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = LegalDataset(X_train, y_train)\n",
    "    test_dataset = LegalDataset(X_test, y_test)\n",
    "\n",
    "    # Initialize RoBERTa model on CPU\n",
    "    num_labels = len(label_map)\n",
    "    model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=num_labels)\n",
    "    device = torch.device('cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Training arguments optimized for CPU\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'./results{suffix}',\n",
    "        num_train_epochs=5 if suffix == '_1' else 3,  # Reduced epochs for Training 1\n",
    "        per_device_train_batch_size=1,  # Single sample per batch\n",
    "        per_device_eval_batch_size=1,\n",
    "        warmup_steps=50,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir=f'./logs{suffix}',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_loss',\n",
    "        greater_is_better=False,\n",
    "        learning_rate=2e-5,\n",
    "        lr_scheduler_type='linear',\n",
    "        gradient_accumulation_steps=1,\n",
    "    )\n",
    "\n",
    "    # Custom trainer with Focal Loss\n",
    "    class FocalTrainer(Trainer):\n",
    "        def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            labels = inputs.get('labels')\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.get('logits')\n",
    "            loss_fct = FocalLoss()\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    trainer = FocalTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=test_dataset,\n",
    "        compute_metrics=lambda eval_pred: {\n",
    "            'accuracy': accuracy_score(eval_pred.label_ids, np.argmax(eval_pred.predictions, axis=1)),\n",
    "            'f1': f1_score(eval_pred.label_ids, np.argmax(eval_pred.predictions, axis=1), average='weighted')\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Train BERT model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate BERT\n",
    "    predictions = trainer.predict(test_dataset)\n",
    "    y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    print(f'\\nBERT Performance (Training {suffix}):')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'F1-Score: {f1:.4f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    unique_labels = np.unique(y_test)\n",
    "    target_names = [list(label_map.keys())[label] for label in unique_labels]\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred, labels=unique_labels, target_names=target_names, zero_division=0))\n",
    "\n",
    "    return model, tokenizer, accuracy, f1, y_pred, y_test, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training 1: Baseline (no balancing, no back-translation)\n",
    "bert_model_1, tokenizer_1, bert_accuracy_1, bert_f1_1, y_pred_bert_1, y_test_bert_1, label_map_bert_1 = run_bert_training(df, '_1', balance=True)\n",
    "\n",
    "# Training 2: Balanced, no back-translation\n",
    "bert_model_2, tokenizer_2, bert_accuracy_2, bert_f1_2, y_pred_bert_2, y_test_bert_2, label_map_bert_2 = run_bert_training(df, '_2', balance=True)\n",
    "\n",
    "# Training 3: Balanced + Back-translation (advanced)\n",
    "bert_model_3, tokenizer_3, bert_accuracy_3, bert_f1_3, y_pred_bert_3, y_test_bert_3, label_map_bert_3 = run_bert_training(df, '_3', balance=True, back_translation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Combined Model Performance Summary\n",
      "\n",
      "| Model             | Training | Accuracy | F1-Score | Precision | Recall  |\n",
      "|-------------------|----------|----------|----------|-----------|---------|\n",
      "| LogisticRegression |    1     |  0.7000  |  0.6978  |  0.7460   | 0.7000  |\n",
      "| RandomForest     |    2     |  0.7000  |  0.6726  |  0.6917   | 0.7000  |\n",
      "| SVM              |    1     |  0.6750  |  0.6691  |  0.7061   | 0.6750  |\n",
      "| LogisticRegression |    2     |  0.6750  |  0.6755  |  0.7125   | 0.6750  |\n",
      "| LogisticRegression |    3     |  0.6750  |  0.6755  |  0.7125   | 0.6750  |\n",
      "| SVM              |    2     |  0.6500  |  0.6491  |  0.6762   | 0.6500  |\n",
      "| SVM              |    3     |  0.6500  |  0.6527  |  0.7146   | 0.6500  |\n",
      "| RandomForest     |    1     |  0.6250  |  0.5220  |  0.6107   | 0.6250  |\n",
      "| RandomForest     |    3     |  0.6250  |  0.5875  |  0.6036   | 0.6250  |\n",
      "| BERT             |    1     |  0.3750  |  0.2830  |  0.2273   | 0.3750  |\n",
      "| BERT             |    3     |  0.2750  |  0.1613  |  0.5735   | 0.2750  |\n",
      "| BERT             |    2     |  0.0500  |  0.0048  |  0.0025   | 0.0500  |\n",
      "\n",
      "**Best Overall Model**: LogisticRegression from Training 1 with Accuracy: 0.7000, F1-Score: 0.6978, Precision: 0.7460, Recall: 0.7000\n"
     ]
    }
   ],
   "source": [
    "# Required imports\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Collect all accuracies, F1-scores, precision, and recall from LR/SVM/RF and BERT trainings\n",
    "all_results = []\n",
    "\n",
    "# Add results from LR/SVM/RF Trainings\n",
    "for suffix, models, vectorizer, model_accuracies, X_test_tfidf, y_test, label_map in [\n",
    "    (1, models_1, vectorizer_1, model_accuracies_1, X_test_tfidf_1, y_test_1, label_map_1),\n",
    "    (2, models_2, vectorizer_2, model_accuracies_2, X_test_tfidf_2, y_test_2, label_map_2),\n",
    "    (3, models_3, vectorizer_3, model_accuracies_3, X_test_tfidf_3, y_test_3, label_map_3)\n",
    "]:\n",
    "    for name, acc in model_accuracies.items():\n",
    "        y_pred = models[name].predict(X_test_tfidf)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "        prec = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "        rec = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "        all_results.append((name, suffix, acc, f1, prec, rec))\n",
    "\n",
    "# Add results from BERT Trainings\n",
    "for suffix, (acc, f1, y_pred, y_test, label_map) in [\n",
    "    (1, (bert_accuracy_1, bert_f1_1, y_pred_bert_1, y_test_bert_1, label_map_bert_1)),\n",
    "    (2, (bert_accuracy_2, bert_f1_2, y_pred_bert_2, y_test_bert_2, label_map_bert_2)),\n",
    "    (3, (bert_accuracy_3, bert_f1_3, y_pred_bert_3, y_test_bert_3, label_map_bert_3))\n",
    "]:\n",
    "    prec = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    all_results.append((\"BERT\", suffix, acc, f1, prec, rec))\n",
    "\n",
    "# Sort by accuracy in descending order\n",
    "sorted_results = sorted(all_results, key=lambda x: x[2], reverse=True)\n",
    "\n",
    "# Display as a Markdown table\n",
    "print(\"\\n### Combined Model Performance Summary\\n\")\n",
    "print(\"| Model             | Training | Accuracy | F1-Score | Precision | Recall  |\")\n",
    "print(\"|-------------------|----------|----------|----------|-----------|---------|\")\n",
    "for model_name, train_num, acc, f1, prec, rec in sorted_results:\n",
    "    print(f\"| {model_name:<16} | {train_num:^8} | {acc:^8.4f} | {f1:^8.4f} | {prec:^9.4f} | {rec:^7.4f} |\")\n",
    "\n",
    "# Identify the best overall model\n",
    "best_model_name, best_training, best_accuracy, best_f1, best_prec, best_rec = sorted_results[0]\n",
    "best_model = (models_1[best_model_name] if best_training == 1 and best_model_name in models_1 else\n",
    "              models_2[best_model_name] if best_training == 2 and best_model_name in models_2 else\n",
    "              models_3[best_model_name] if best_training == 3 and best_model_name in models_3 else None)\n",
    "best_vectorizer = (vectorizer_1 if best_training == 1 and best_model_name != \"BERT\" else\n",
    "                   vectorizer_2 if best_training == 2 and best_model_name != \"BERT\" else\n",
    "                   vectorizer_3 if best_training == 3 and best_model_name != \"BERT\" else None)\n",
    "best_X_test = (X_test_tfidf_1 if best_training == 1 and best_model_name != \"BERT\" else\n",
    "               X_test_tfidf_2 if best_training == 2 and best_model_name != \"BERT\" else\n",
    "               X_test_tfidf_3 if best_training == 3 and best_model_name != \"BERT\" else None)\n",
    "best_y_test = (y_test_1 if best_training == 1 and best_model_name != \"BERT\" else\n",
    "               y_test_2 if best_training == 2 and best_model_name != \"BERT\" else\n",
    "               y_test_3 if best_training == 3 and best_model_name != \"BERT\" else\n",
    "               y_test_bert_1 if best_training == 1 else\n",
    "               y_test_bert_2 if best_training == 2 else y_test_bert_3)\n",
    "best_label_map = (label_map_1 if best_training == 1 and best_model_name != \"BERT\" else\n",
    "                  label_map_2 if best_training == 2 and best_model_name != \"BERT\" else\n",
    "                  label_map_3 if best_training == 3 and best_model_name != \"BERT\" else\n",
    "                  label_map_bert_1 if best_training == 1 else\n",
    "                  label_map_bert_2 if best_training == 2 else label_map_bert_3)\n",
    "\n",
    "print(f\"\\n**Best Overall Model**: {best_model_name} from Training {best_training} with Accuracy: {best_accuracy:.4f}, F1-Score: {best_f1:.4f}, Precision: {best_prec:.4f}, Recall: {best_rec:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best LR/SVM/RF Model: LogisticRegression from Training 1 with Accuracy: 0.7000\n",
      "Best BERT Model: BERT from Training 1 with Accuracy: 0.3750\n",
      "Saved LR/SVM/RF model and vectorizer successfully.\n",
      "Saved BERT model, tokenizer, and label map successfully.\n",
      "Memory cleanup completed. Process memory usage: 968.26 MB\n"
     ]
    }
   ],
   "source": [
    "# Combine accuracies from all LR/SVM/RF trainings\n",
    "all_lr_accuracies = {}\n",
    "\n",
    "# Training 1\n",
    "for name, acc in model_accuracies_1.items():\n",
    "    all_lr_accuracies[(name, 1)] = (acc, models_1[name], vectorizer_1, X_test_tfidf_1, y_test_1, label_map_1)\n",
    "\n",
    "# Training 2\n",
    "for name, acc in model_accuracies_2.items():\n",
    "    all_lr_accuracies[(name, 2)] = (acc, models_2[name], vectorizer_2, X_test_tfidf_2, y_test_2, label_map_2)\n",
    "\n",
    "# Training 3\n",
    "for name, acc in model_accuracies_3.items():\n",
    "    all_lr_accuracies[(name, 3)] = (acc, models_3[name], vectorizer_3, X_test_tfidf_3, y_test_3, label_map_3)\n",
    "\n",
    "# Find the best LR/SVM/RF model\n",
    "best_lr_key = max(all_lr_accuracies, key=lambda k: all_lr_accuracies[k][0])\n",
    "best_lr_model_name, lr_training_number = best_lr_key\n",
    "best_lr_accuracy, best_lr_model, best_lr_vectorizer, best_lr_X_test, best_lr_y_test, best_lr_label_map = all_lr_accuracies[best_lr_key]\n",
    "best_lr_predictions = best_lr_model.predict(best_lr_X_test)\n",
    "\n",
    "print(f\"\\nBest LR/SVM/RF Model: {best_lr_model_name} from Training {lr_training_number} with Accuracy: {best_lr_accuracy:.4f}\")\n",
    "\n",
    "# Combine accuracies from all BERT trainings\n",
    "all_bert_accuracies = {\n",
    "    ('BERT', 1): (bert_accuracy_1, bert_model_1, tokenizer_1, y_pred_bert_1, y_test_bert_1, label_map_bert_1),\n",
    "    ('BERT', 2): (bert_accuracy_2, bert_model_2, tokenizer_2, y_pred_bert_2, y_test_bert_2, label_map_bert_2),\n",
    "    ('BERT', 3): (bert_accuracy_3, bert_model_3, tokenizer_3, y_pred_bert_3, y_test_bert_3, label_map_bert_3)\n",
    "}\n",
    "\n",
    "# Find the best BERT model\n",
    "best_bert_key = max(all_bert_accuracies, key=lambda k: all_bert_accuracies[k][0])\n",
    "best_bert_model_name, bert_training_number = best_bert_key\n",
    "best_bert_accuracy, best_bert_model, best_bert_tokenizer, best_bert_predictions, best_bert_y_test, best_bert_label_map = all_bert_accuracies[best_bert_key]\n",
    "\n",
    "print(f\"Best BERT Model: {best_bert_model_name} from Training {bert_training_number} with Accuracy: {best_bert_accuracy:.4f}\")\n",
    "\n",
    "# Ensure the models directory exists\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save the best LR/SVM/RF model and vectorizer\n",
    "try:\n",
    "    with open('../models/saved_lr_model.pkl', 'wb') as f:\n",
    "        pickle.dump(best_lr_model, f)\n",
    "    with open('../models/lr_vectorizer.pkl', 'wb') as f:\n",
    "        pickle.dump(best_lr_vectorizer, f)\n",
    "    print(\"Saved LR/SVM/RF model and vectorizer successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving LR/SVM/RF model or vectorizer: {e}\")\n",
    "\n",
    "# Save the best BERT model and tokenizer\n",
    "try:\n",
    "    best_bert_model.save_pretrained('../models/best_bert_model')\n",
    "    best_bert_tokenizer.save_pretrained('../models/best_bert_tokenizer')\n",
    "    with open('../models/best_bert_label_map.json', 'w') as f:\n",
    "        json.dump(best_bert_label_map, f)\n",
    "    print(\"Saved BERT model, tokenizer, and label map successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving BERT model or tokenizer: {e}\")\n",
    "\n",
    "# Clear memory\n",
    "gc.collect()\n",
    "print(f\"Memory cleanup completed. Process memory usage: {psutil.Process().memory_info().rss / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Results and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Visualize confusion matrices\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Confusion Matrix for Best BERT Model\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.heatmap(confusion_matrix(best_bert_y_test, best_bert_predictions), annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=best_bert_label_map.keys(), yticklabels=best_bert_label_map.keys())\n",
    "plt.title(f'Confusion Matrix - Best BERT (Training {bert_training_number})')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Confusion Matrix for Best LR/SVM/RF Model\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.heatmap(confusion_matrix(best_lr_y_test, best_lr_predictions), annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=best_lr_label_map.keys(), yticklabels=best_lr_label_map.keys())\n",
    "plt.title(f'Confusion Matrix - Best {best_lr_model_name} (Training {lr_training_number})')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../visuals/confusion_matrices.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot Accuracy Comparison\n",
    "plt.figure(figsize=(8, 5))\n",
    "models = [f'{best_lr_model_name} (Training {lr_training_number})', f'BERT (Training {bert_training_number})']\n",
    "accuracies = [best_lr_accuracy, best_bert_accuracy]\n",
    "sns.barplot(x=accuracies, y=models, palette='Blues_d')\n",
    "plt.title('Accuracy Comparison of Best Models')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.xlim(0, 1)\n",
    "for i, v in enumerate(accuracies):\n",
    "    plt.text(v + 0.01, i, f'{v:.4f}', va='center')\n",
    "plt.savefig('../visuals/accuracy_comparison.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "- **Preprocessing**: Cleaned `full_report` and extracted labels with a comprehensive keyword approach, reducing the 'Other' category. Handled imbalance with SMOTE for TF-IDF models.\n",
    "- **Modeling**: TF-IDF with Logistic Regression achieved 0.7500 accuracy; BERT reached 0.5000 accuracy with 5 epochs and class weighting.\n",
    "- **Evaluation**: Detailed metrics and visualizations provided.\n",
    "- **API**: Implemented in `app/api.py` using the Logistic Regression model.\n",
    "- **Future Work**: Fine-tune BERT with more data, explore Legal-BERT, and optimize API with Docker."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
